---
title: R 機械学習モデルを使用したリアルタイム スコアリング
description: Azure Kubernetes Service (AKS) で実行される Machine Learning Server を使用して、R のリアルタイム予測サービスを実装します。
author: njray
ms.date: 12/12/18
ms.custom: azcat-ai
ms.openlocfilehash: a6069704c48fbc1f1a1e4b5df428011d6b5b883d
ms.sourcegitcommit: 62d2211badd1d6950e8cb819d70c9a4ab1ee01d9
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 12/12/2018
ms.locfileid: "53318994"
---
# <a name="real-time-scoring-of-r-machine-learning-models"></a><span data-ttu-id="236af-103">R 機械学習モデルを使用したリアルタイム スコアリング</span><span class="sxs-lookup"><span data-stu-id="236af-103">Real-time scoring of R machine learning models</span></span>

<span data-ttu-id="236af-104">このリファレンス アーキテクチャでは、Azure Kubernetes Service (AKS) で実行される Microsoft Machine Learning Server を使用して、R のリアルタイム (同期) 予測サービスを実装する方法を示しています。</span><span class="sxs-lookup"><span data-stu-id="236af-104">This reference architecture shows how to implement a real-time (synchronous) prediction service in R using Microsoft Machine Learning Server running in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="236af-105">このアーキテクチャは、汎用性があり、リアルタイム サービスとしてデプロイするつもりの、R で構築されるすべての予測モデルに適するように設計されています。</span><span class="sxs-lookup"><span data-stu-id="236af-105">This architecture is intended to be generic and suited for any predictive model built in R that you want to deploy as a real-time service.</span></span> <span data-ttu-id="236af-106">**[このソリューションをデプロイする][github]**。</span><span class="sxs-lookup"><span data-stu-id="236af-106">**[Deploy this solution][github]**.</span></span>

## <a name="architecture"></a><span data-ttu-id="236af-107">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="236af-107">Architecture</span></span>

![Azure で R 機械学習モデルを使用したリアルタイム スコアリング][0]

<span data-ttu-id="236af-109">このリファレンス アーキテクチャでは、コンテナー ベースのアプローチを採用しています。</span><span class="sxs-lookup"><span data-stu-id="236af-109">This reference architecture takes a container-based approach.</span></span> <span data-ttu-id="236af-110">新しいデータのスコア付けに必要なさまざまな成果物はもちろん、R を含む Docker イメージが構築されます。</span><span class="sxs-lookup"><span data-stu-id="236af-110">A Docker image is built containing R, as well as the various artifacts needed to score new data.</span></span> <span data-ttu-id="236af-111">これには、モデル オブジェクト自体とスコアリング スクリプトが含まれます。</span><span class="sxs-lookup"><span data-stu-id="236af-111">These include the model object itself and a scoring script.</span></span> <span data-ttu-id="236af-112">このイメージは、Azure でホストされている Docker レジストリにプッシュされた後、同様に Azure 内にある Kubernetes クラスターにデプロイされます。</span><span class="sxs-lookup"><span data-stu-id="236af-112">This image is pushed to a Docker registry hosted in Azure, and then deployed to a Kubernetes cluster, also in Azure.</span></span>

<span data-ttu-id="236af-113">このワークフローのアーキテクチャには、以下のコンポーネントが含まれています。</span><span class="sxs-lookup"><span data-stu-id="236af-113">The architecture of this workflow includes the following components.</span></span>

- <span data-ttu-id="236af-114">**[Azure Container Registry][acr]** は、このワークフローのイメージを格納するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="236af-114">**[Azure Container Registry][acr]** is used to store the images for this workflow.</span></span> <span data-ttu-id="236af-115">Container Registry で作成されたレジストリは、標準の [Docker Registry V2 API][docker] とクライアントを使用して管理できます。</span><span class="sxs-lookup"><span data-stu-id="236af-115">Registries created with Container Registry can be managed via the standard [Docker Registry V2 API][docker] and client.</span></span>

- <span data-ttu-id="236af-116">**[Azure Kubernetes Service][aks]** は、デプロイとサービスをホストするために使用されます。</span><span class="sxs-lookup"><span data-stu-id="236af-116">**[Azure Kubernetes Service][aks]** is used to host the deployment and service.</span></span> <span data-ttu-id="236af-117">AKS で作成されたクラスターは、標準の [Kubernetes API][k-api] とクライアント (kubectl) を使用して管理できます。</span><span class="sxs-lookup"><span data-stu-id="236af-117">Clusters created with AKS can be managed using the standard [Kubernetes API][k-api] and client (kubectl).</span></span>

- <span data-ttu-id="236af-118">**[Microsoft Machine Learning Server][mmls]** は、サービスの REST API を定義するために使用され、[モデルの運用化][operationalization]を含んでいます。</span><span class="sxs-lookup"><span data-stu-id="236af-118">**[Microsoft Machine Learning Server][mmls]** is used to define the REST API for the service and includes [Model Operationalization][operationalization].</span></span> <span data-ttu-id="236af-119">このサービス指向の Web サーバー プロセスが要求をリッスンし、要求はその後、結果を生成する実際の R コードを実行する他のバックグラウンド プロセスに渡されます。</span><span class="sxs-lookup"><span data-stu-id="236af-119">This service-oriented web server process listens for requests, which are then handed off to other background processes that run the actual R code to generate the results.</span></span> <span data-ttu-id="236af-120">これらのプロセスはすべて、この構成ではコンテナーにラップされている 1 つのノードで実行されます。</span><span class="sxs-lookup"><span data-stu-id="236af-120">All these processes run on a single node in this configuration, which is wrapped in a container.</span></span> <span data-ttu-id="236af-121">開発環境やテスト環境の外でこのサービスを使用することの詳細については、Microsoft の担当者に問い合わせてください。</span><span class="sxs-lookup"><span data-stu-id="236af-121">For details about using this service outside a dev or test environment, contact your Microsoft representative.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="236af-122">パフォーマンスに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="236af-122">Performance considerations</span></span>

<span data-ttu-id="236af-123">機械学習のワークロードは、トレーニング時と新しいデータのスコアリング時のどちらでも、多くのコンピューティング処理を要する傾向があります。</span><span class="sxs-lookup"><span data-stu-id="236af-123">Machine learning workloads tend to be compute-intensive, both when training and when scoring new data.</span></span> <span data-ttu-id="236af-124">一般的に、コアあたり 1 つより多いスコアリング プロセスを実行しないようにしてください。</span><span class="sxs-lookup"><span data-stu-id="236af-124">As a rule of thumb, try not to run more than one scoring process per core.</span></span> <span data-ttu-id="236af-125">Machine Learning Server では、各コンテナーで実行される R プロセスの数を定義できます。</span><span class="sxs-lookup"><span data-stu-id="236af-125">Machine Learning Server lets you define the number of R processes running in each container.</span></span> <span data-ttu-id="236af-126">既定では 5 つのプロセスです。</span><span class="sxs-lookup"><span data-stu-id="236af-126">The default is five processes.</span></span> <span data-ttu-id="236af-127">変数の数が少ない線形回帰や、小さなデシジョン ツリーなどの比較的単純なモデルを作成するときには、プロセスの数を増やすことができます。</span><span class="sxs-lookup"><span data-stu-id="236af-127">When creating a relatively simple model, such as a linear regression with a small number of variables, or a small decision tree, you can increase the number of processes.</span></span> <span data-ttu-id="236af-128">クラスター ノードでの CPU 負荷を監視して、コンテナーの数に関する適切な上限を決定します。</span><span class="sxs-lookup"><span data-stu-id="236af-128">Monitor the CPU load on your cluster nodes to determine the appropriate limit on the number of containers.</span></span>

<span data-ttu-id="236af-129">GPU 対応クラスターは、一部の種類のワークロード、特にディープ ラーニング モデルを高速化できます。</span><span class="sxs-lookup"><span data-stu-id="236af-129">A GPU-enabled cluster can speed up some types of workloads, and deep learning models in particular.</span></span> <span data-ttu-id="236af-130">すべてのワークロードが GPU を活用できるわけではなく、それが可能なのはマトリックス代数を大量に使用するワークロードのみです。</span><span class="sxs-lookup"><span data-stu-id="236af-130">Not all workloads can take advantage of GPUs &mdash; only those that make heavy use of matrix algebra.</span></span> <span data-ttu-id="236af-131">たとえば、ランダム フォレスト モデルやブースティング モデルを含むツリー ベースのモデルは、一般に、GPU から利点を引き出せません。</span><span class="sxs-lookup"><span data-stu-id="236af-131">For example, tree-based models, including random forests and boosting models, generally derive no advantage from GPUs.</span></span>

<span data-ttu-id="236af-132">ランダム フォレストなど、いくつかの種類のモデルは、CPU で大規模な並列化が可能です。</span><span class="sxs-lookup"><span data-stu-id="236af-132">Some model types such as random forests are massively parallelizable on CPUs.</span></span> <span data-ttu-id="236af-133">このような場合は、複数のコア間でワークロードを分散させることにで、1 つの要求のスコアリングを高速化します。</span><span class="sxs-lookup"><span data-stu-id="236af-133">In these cases, speed up the scoring of a single request by distributing the workload across multiple cores.</span></span> <span data-ttu-id="236af-134">ただしそのようにすると、固定のクラスター サイズを指定された複数のスコアリング要求を処理するキャパシティが減少します。</span><span class="sxs-lookup"><span data-stu-id="236af-134">However, doing so reduces your capacity to handle multiple scoring requests given a fixed cluster size.</span></span>

<span data-ttu-id="236af-135">一般に、オープン ソースの R モデルでは、すべてのデータがメモリ内に格納されるため、同時に実行する予定のプロセスに対応するために十分なメモリがノードにあることを確認します。</span><span class="sxs-lookup"><span data-stu-id="236af-135">In general, open-source R models store all their data in memory, so ensure that your nodes have enough memory to accommodate the processes you plan to run concurrently.</span></span> <span data-ttu-id="236af-136">モデルに合わせて Machine Learning Server を使おうとしている場合は、メモリにすべてを読み込むのではなく、ディスク上のデータを処理できるライブラリを使用します。</span><span class="sxs-lookup"><span data-stu-id="236af-136">If you are using Machine Learning Server to fit your models, use the libraries that can process data on disk, rather than reading it all into memory.</span></span> <span data-ttu-id="236af-137">これは、メモリの要件を大幅に引き下げる助けになります。</span><span class="sxs-lookup"><span data-stu-id="236af-137">This can help reduce memory requirements significantly.</span></span> <span data-ttu-id="236af-138">Machine Learning Server とオープン ソースの R のどちらを使用するかに関わらず、ノードを監視して、スコアリング プロセスでメモリが不足していないことを確認します。</span><span class="sxs-lookup"><span data-stu-id="236af-138">Regardless of whether you use Machine Learning Server or open-source R, monitor your nodes to ensure that your scoring processes are not memory-starved.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="236af-139">セキュリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="236af-139">Security considerations</span></span>

### <a name="network-encryption"></a><span data-ttu-id="236af-140">ネットワークの暗号化</span><span class="sxs-lookup"><span data-stu-id="236af-140">Network encryption</span></span>

<span data-ttu-id="236af-141">このリファレンス アーキテクチャでは、クラスターとの通信では HTTPS が有効になっていて、[Let's Encrypt][encrypt] のステージング証明書が使用されています。</span><span class="sxs-lookup"><span data-stu-id="236af-141">In this reference architecture, HTTPS is enabled for communication with the cluster, and a staging certificate from [Let’s Encrypt][encrypt] is used.</span></span> <span data-ttu-id="236af-142">運用目的の場合は、適切な署名機関から入手した独自の証明書に置き換えてください。</span><span class="sxs-lookup"><span data-stu-id="236af-142">For production purposes, substitute your own certificate from an appropriate signing authority.</span></span>

### <a name="authentication-and-authorization"></a><span data-ttu-id="236af-143">認証と権限承認</span><span class="sxs-lookup"><span data-stu-id="236af-143">Authentication and authorization</span></span>

<span data-ttu-id="236af-144">Machine Learning Server の[モデルの運用化][operationalization]を使用するには、スコアリング要求が認証される必要があります。</span><span class="sxs-lookup"><span data-stu-id="236af-144">Machine Learning Server [Model Operationalization][operationalization] requires scoring requests to be authenticated.</span></span> <span data-ttu-id="236af-145">このデプロイでは、ユーザー名とパスワードが使用されます。</span><span class="sxs-lookup"><span data-stu-id="236af-145">In this deployment, a username and password are used.</span></span> <span data-ttu-id="236af-146">企業での設定では、[Azure Active Directory][AAD] を使用して認証を有効にするか、[Azure API Management][API] を使用して別のフロント エンドを作成します。</span><span class="sxs-lookup"><span data-stu-id="236af-146">In an enterprise setting, you can enable authentication using [Azure Active Directory][AAD] or create a separate front end using [Azure API Management][API].</span></span>

<span data-ttu-id="236af-147">モデルの運用化をコンテナー上の Machine Learning Server で正しく機能させるには、JSON Web トークン (JWT) の証明書をインストールする必要があります。</span><span class="sxs-lookup"><span data-stu-id="236af-147">For Model Operationalization to work correctly with Machine Learning Server on containers, you must install a JSON Web Token (JWT) certificate.</span></span> <span data-ttu-id="236af-148">このデプロイでは、Microsoft が提供する証明書を使用しています。</span><span class="sxs-lookup"><span data-stu-id="236af-148">This deployment uses a certificate supplied by Microsoft.</span></span> <span data-ttu-id="236af-149">運用環境の設定では、独自のものを提供してください。</span><span class="sxs-lookup"><span data-stu-id="236af-149">In a production setting, supply your own.</span></span>

<span data-ttu-id="236af-150">Container Registry と AKS 間のトラフィックについては、[ロール ベースのアクセス制御][rbac] (RBAC) を有効にして、必要なものだけにアクセス特権を制限します。</span><span class="sxs-lookup"><span data-stu-id="236af-150">For traffic between Container Registry and AKS, consider enabling [role-based access control][rbac] (RBAC) to limit access privileges to only those needed.</span></span> 

### <a name="separate-storage"></a><span data-ttu-id="236af-151">別個のストレージ</span><span class="sxs-lookup"><span data-stu-id="236af-151">Separate storage</span></span>

<span data-ttu-id="236af-152">このリファレンス アーキテクチャでは、1 つのイメージにアプリケーション (R) とデータ (モデル オブジェクトとスコアリング スクリプト) がまとめられています。</span><span class="sxs-lookup"><span data-stu-id="236af-152">This reference architecture bundles the application (R) and the data (model object and scoring script) into a single image.</span></span> <span data-ttu-id="236af-153">場合によっては、これらを分けるメリットがあります。</span><span class="sxs-lookup"><span data-stu-id="236af-153">In some cases, it may be beneficial to separate these.</span></span> <span data-ttu-id="236af-154">モデルのデータとコードを Azure の BLOB やファイル [ストレージ][storage]に配置し、コンテナーの初期化時にそれらを取得します。</span><span class="sxs-lookup"><span data-stu-id="236af-154">You can place the model data and code into Azure blob or file [storage][storage], and retrieve them at container initialization.</span></span> <span data-ttu-id="236af-155">この場合は、ストレージ アカウントが、認証されたアクセスのみを許可し、HTTPS を要求するように設定されていることを確認します。</span><span class="sxs-lookup"><span data-stu-id="236af-155">In this case, ensure that the storage account is set to allow authenticated access only and require HTTPS.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="236af-156">監視とログ記録に関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="236af-156">Monitoring and logging considerations</span></span>

<span data-ttu-id="236af-157">[Kubernetes ダッシュ ボード][dashboard]使用して、AKS クラスターの全体的な状態を監視します。</span><span class="sxs-lookup"><span data-stu-id="236af-157">Use the [Kubernetes dashboard][dashboard] to monitor the overall status of your AKS cluster.</span></span> <span data-ttu-id="236af-158">詳細については、Azure portal でクラスターの概要ブレードを参照してください。</span><span class="sxs-lookup"><span data-stu-id="236af-158">See the cluster’s overview blade in Azure portal for more details.</span></span> <span data-ttu-id="236af-159">[GitHub][github] のリソースにも、R からダッシュ ボードを表示する方法が示されています。</span><span class="sxs-lookup"><span data-stu-id="236af-159">The [GitHub][github] resources also show how to bring up the dashboard from R.</span></span>

<span data-ttu-id="236af-160">ダッシュ ボードには、クラスターの全体的な正常性のビューが表示されますが、個々のコンテナーの状態を追跡することも重要です。</span><span class="sxs-lookup"><span data-stu-id="236af-160">Although the dashboard gives you a view of the overall health of your cluster, it’s also important to track the status of individual containers.</span></span> <span data-ttu-id="236af-161">これを行うには、Azure portal でクラスターの概要ブレードから [Azure Monitor Insights][monitor] を有効にします。または、[コンテナー用の Azure Monitor][monitor-containers] (プレビュー段階) についてのページを参照してください。</span><span class="sxs-lookup"><span data-stu-id="236af-161">To do this, enable [Azure Monitor Insights][monitor] from the cluster overview blade in Azure portal, or see [Azure Monitor for containers][monitor-containers] (in preview).</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="236af-162">コストに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="236af-162">Cost considerations</span></span>

<span data-ttu-id="236af-163">Machine Learning Server は、コア単位でライセンスされます。クラスター内で Machine Learning Server を実行するすべてのコアがこれに加算されます。</span><span class="sxs-lookup"><span data-stu-id="236af-163">Machine Learning Server is licensed on a per-core basis, and all the cores in the cluster that will run Machine Learning  Server count towards this.</span></span> <span data-ttu-id="236af-164">Machine Learning Server または Microsoft SQL Server を使用する企業のお客様の場合は、料金の詳細について、マイクロソフトの担当者にお問い合わせください。</span><span class="sxs-lookup"><span data-stu-id="236af-164">If you are an enterprise Machine Learning Server or Microsoft SQL Server customer, contact your Microsoft representative for pricing details.</span></span>

<span data-ttu-id="236af-165">Machine Learning Server のオープン ソース代替品として、[Plumber][plumber] があります、これは、コードを REST API に変換する R パッケージです。</span><span class="sxs-lookup"><span data-stu-id="236af-165">An open-source alternative to Machine Learning Server is [Plumber][plumber], an R package that turns your code into a REST API.</span></span> <span data-ttu-id="236af-166">Plumber に備わる機能は Machine Learning Server よりも少なくなっています。</span><span class="sxs-lookup"><span data-stu-id="236af-166">Plumber is less fully featured than Machine Learning Server.</span></span> <span data-ttu-id="236af-167">たとえば、要求の認証を提供する機能は、既定では一切含まれません。</span><span class="sxs-lookup"><span data-stu-id="236af-167">For example, by default it doesn't include any features that provide request authentication.</span></span> <span data-ttu-id="236af-168">Plumber を使用する場合は、[Azure API Management][API] を有効にして認証の細部を処理することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="236af-168">If you use Plumber, it’s recommended that you enable [Azure API Management][API] to handle authentication details.</span></span>

<span data-ttu-id="236af-169">ライセンス以外のコストに関する主な考慮事項は、Kubernetes クラスターのコンピューティング リソースです。</span><span class="sxs-lookup"><span data-stu-id="236af-169">Besides licensing, the main cost consideration is the Kubernetes cluster's compute resources.</span></span> <span data-ttu-id="236af-170">クラスターは、ピーク時に予想される要求量を処理するために十分なサイズである必要がありますが、この手法では、その他のときにリソースがアイドル状態に残されます。</span><span class="sxs-lookup"><span data-stu-id="236af-170">The cluster must be large enough to handle the expected request volume at peak times, but this approach leaves resources idle at other times.</span></span> <span data-ttu-id="236af-171">アイドル状態のリソースの影響を限定するには、kubectl ツールを使用して、クラスターに対して[水平オートスケーラー][autoscaler]を有効にします。</span><span class="sxs-lookup"><span data-stu-id="236af-171">To limit the impact of idle resources, enable the [horizontal autoscaler][autoscaler] for the cluster using the kubectl tool.</span></span> <span data-ttu-id="236af-172">または、AKS の[クラスター オートスケーラー][cluster-autoscaler]を使用します。</span><span class="sxs-lookup"><span data-stu-id="236af-172">Or use the AKS [cluster autoscaler][cluster-autoscaler].</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="236af-173">ソリューションのデプロイ方法</span><span class="sxs-lookup"><span data-stu-id="236af-173">Deploy the solution</span></span>

<span data-ttu-id="236af-174">このアーキテクチャのリファレンス実装は、[GitHub][github] で入手できます。</span><span class="sxs-lookup"><span data-stu-id="236af-174">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="236af-175">そこで説明されている手順に従って、単純な予測モデルをサービスとしてデプロイします。</span><span class="sxs-lookup"><span data-stu-id="236af-175">Follow the steps described there to deploy a simple predictive model as a service.</span></span>

<!-- links -->
[AAD]: /azure/active-directory/fundamentals/active-directory-whatis
[API]: /azure/api-management/api-management-key-concepts
[ACR]: /azure/container-registry/container-registry-intro
[AKS]: /azure/aks/intro-kubernetes
[autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[cluster-autoscaler]: /azure/aks/autoscaler
[monitor]: /azure/monitoring/monitoring-container-insights-overview
[dashboard]: /azure/aks/kubernetes-dashboard
[docker]: https://docs.docker.com/registry/spec/api/
[encrypt]: https://letsencrypt.org/
[gitHub]: https://github.com/Azure/RealtimeRDeployment
[K-API]: https://kubernetes.io/docs/reference/
[MMLS]: /machine-learning-server/what-is-machine-learning-server
[monitor-containers]: /azure/azure-monitor/insights/container-insights-overview
[operationalization]: /machine-learning-server/what-is-operationalization
[plumber]: https://www.rplumber.io
[RBAC]: /azure/role-based-access-control/overview
[storage]: /azure/storage/common/storage-introduction
[0]: ./_images/realtime-scoring-r.png
