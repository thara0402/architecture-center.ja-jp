---
title: ディープ ラーニング モデル用のバッチ スコアリング
titleSuffix: Azure Reference Architectures
description: この参照アーキテクチャでは、Azure Machine Learning を使用してニューラル スタイルの転送を動画に適用する方法を示します。
author: jiata
ms.date: 02/06/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 85d04f179b988fd5b00b361149f2170d13608e6d
ms.sourcegitcommit: 700a4f6ce61b1ebe68e227fc57443e49282e35aa
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 02/07/2019
ms.locfileid: "55887388"
---
# <a name="batch-scoring-on-azure-for-deep-learning-models"></a><span data-ttu-id="4c120-103">ディープ ラーニング モデル用の Azure でのバッチ スコアリング</span><span class="sxs-lookup"><span data-stu-id="4c120-103">Batch scoring on Azure for deep learning models</span></span>

<span data-ttu-id="4c120-104">この参照アーキテクチャでは、Azure Machine Learning を使用してニューラル スタイルの転送を動画に適用する方法を示します。</span><span class="sxs-lookup"><span data-stu-id="4c120-104">This reference architecture shows how to apply neural style transfer to a video, using Azure Machine Learning.</span></span> <span data-ttu-id="4c120-105">"*スタイルの転送*" とは、別の画像のスタイルに既存の画像を組み込むディープ ラーニングの手法です。</span><span class="sxs-lookup"><span data-stu-id="4c120-105">*Style transfer* is a deep learning technique that composes an existing image in the style of another image.</span></span> <span data-ttu-id="4c120-106">このアーキテクチャは、ディープ ラーニングでバッチ スコアリングを使用する任意のシナリオに一般化することができます。</span><span class="sxs-lookup"><span data-stu-id="4c120-106">This architecture can be generalized for any scenario that uses batch scoring with deep learning.</span></span> <span data-ttu-id="4c120-107">[**このソリューションをデプロイします**](#deploy-the-solution)。</span><span class="sxs-lookup"><span data-stu-id="4c120-107">[**Deploy this solution**](#deploy-the-solution).</span></span>

![Azure Machine Learning を使用したディープ ラーニング モデルのアーキテクチャ ダイアグラム](./_images/aml-scoring-deep-learning.png)

<span data-ttu-id="4c120-109">**シナリオ**: あるメディア組織は、動画のスタイルを特定の絵画のように変更したいと考えています。</span><span class="sxs-lookup"><span data-stu-id="4c120-109">**Scenario**: A media organization has a video whose style they want to change to look like a specific painting.</span></span> <span data-ttu-id="4c120-110">組織は、適切なタイミングで自動的に動画のすべてのフレームにこのスタイルを適用できることを望んでいます。</span><span class="sxs-lookup"><span data-stu-id="4c120-110">The organization wants to be able to apply this style to all frames of the video in a timely manner and in an automated fashion.</span></span> <span data-ttu-id="4c120-111">ニューラル スタイル転送アルゴリズムの背景について詳しくは、「[Image Style Transfer Using Convolutional Neural Networks][image-style-transfer]」(畳み込みニューラル ネットワークを使用した画像スタイルの転送) (PDF) をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="4c120-111">For more background about neural style transfer algorithms, see [Image Style Transfer Using Convolutional Neural Networks][image-style-transfer] (PDF).</span></span>

| <span data-ttu-id="4c120-112">スタイル画像:</span><span class="sxs-lookup"><span data-stu-id="4c120-112">Style image:</span></span> | <span data-ttu-id="4c120-113">入力/コンテンツ動画:</span><span class="sxs-lookup"><span data-stu-id="4c120-113">Input/content video:</span></span> | <span data-ttu-id="4c120-114">出力動画:</span><span class="sxs-lookup"><span data-stu-id="4c120-114">Output video:</span></span> |
|--------|--------|---------|
| <img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/style_image.jpg" width="300"> | <span data-ttu-id="4c120-115">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video.mp4 "入力動画") *クリックすると動画が表示されます*</span><span class="sxs-lookup"><span data-stu-id="4c120-115">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video.mp4 "Input Video") *click to view video*</span></span> | <span data-ttu-id="4c120-116">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video.mp4 "出力動画") *クリックすると動画が表示されます*</span><span class="sxs-lookup"><span data-stu-id="4c120-116">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video.mp4 "Output Video") *click to view video*</span></span> |

<span data-ttu-id="4c120-117">この参照アーキテクチャは、Azure Storage に新しいメディアが存在することによってトリガーされるワークロード用に設計されています。</span><span class="sxs-lookup"><span data-stu-id="4c120-117">This reference architecture is designed for workloads that are triggered by the presence of new media in Azure storage.</span></span>

<span data-ttu-id="4c120-118">処理には次の手順が含まれます。</span><span class="sxs-lookup"><span data-stu-id="4c120-118">Processing involves the following steps:</span></span>

1. <span data-ttu-id="4c120-119">動画ファイルをアップロードします。</span><span class="sxs-lookup"><span data-stu-id="4c120-119">Upload a video file to storage.</span></span>
1. <span data-ttu-id="4c120-120">動画ファイルによってロジック アプリがトリガーされ、Azure Machine Learning パイプラインで公開されているエンドポイントに要求が送信されます。</span><span class="sxs-lookup"><span data-stu-id="4c120-120">The video file triggers a Logic App to send a request to the Azure Machine Learning pipeline published endpoint.</span></span>
1. <span data-ttu-id="4c120-121">パイプラインによって動画が処理され、MPI を使用してスタイル転送が適用され、動画が後処理されます。</span><span class="sxs-lookup"><span data-stu-id="4c120-121">The pipeline processes the video, applies style transfer with MPI, and postprocesses the video.</span></span>
1. <span data-ttu-id="4c120-122">パイプラインが完了すると、出力が Blob Storage に保存されます。</span><span class="sxs-lookup"><span data-stu-id="4c120-122">The output is saved back to blob storage once the pipeline is completed.</span></span>

## <a name="architecture"></a><span data-ttu-id="4c120-123">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="4c120-123">Architecture</span></span>

<span data-ttu-id="4c120-124">このアーキテクチャは、次のコンポーネントで構成されます。</span><span class="sxs-lookup"><span data-stu-id="4c120-124">This architecture consists of the following components.</span></span>

### <a name="compute"></a><span data-ttu-id="4c120-125">Compute</span><span class="sxs-lookup"><span data-stu-id="4c120-125">Compute</span></span>

<span data-ttu-id="4c120-126">**[Azure Machine Learning service][amls]** は、Azure Machine Learning Pipelines を使用して、再現可能で管理が容易な計算シーケンスを作成します。</span><span class="sxs-lookup"><span data-stu-id="4c120-126">**[Azure Machine Learning Service][amls]** uses Azure Machine Learning Pipelines to create reproducible and easy-to-manage sequences of computation.</span></span> <span data-ttu-id="4c120-127">また、[Azure Machine Learning コンピューティング][aml-compute]という、機械学習モデルのトレーニング、デプロイ、およびスコアリングのためのマネージド コンピューティング先 (これに対してパイプラインの計算が実行されます) も提供します。</span><span class="sxs-lookup"><span data-stu-id="4c120-127">It also offers a managed compute target (on which a pipeline computation can run) called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span> 

### <a name="storage"></a><span data-ttu-id="4c120-128">Storage</span><span class="sxs-lookup"><span data-stu-id="4c120-128">Storage</span></span>

<span data-ttu-id="4c120-129">**[Blob Storage][blob-storage]** は、すべての画像 (入力画像、スタイル画像、出力画像) を格納するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="4c120-129">**[Blob storage][blob-storage]** is used to store all images (input images, style images, and output images).</span></span> <span data-ttu-id="4c120-130">Azure Machine Learning service は、ユーザーがコンピューティング プラットフォームと Blob Storage の間でデータを手動で移動する必要がないように、Blob Storage と統合されています。</span><span class="sxs-lookup"><span data-stu-id="4c120-130">Azure Machine Learning Service integrates with Blob storage so that users do not have to manually move data across compute platforms and Blob storage.</span></span> <span data-ttu-id="4c120-131">BLOB ストレージは、このワークロードに必要なパフォーマンスに対してコスト効率も非常に優れています。</span><span class="sxs-lookup"><span data-stu-id="4c120-131">Blob storage is also very cost-effective for the performance that this workload requires.</span></span>

### <a name="trigger--scheduling"></a><span data-ttu-id="4c120-132">トリガー/スケジュール</span><span class="sxs-lookup"><span data-stu-id="4c120-132">Trigger / scheduling</span></span>

<span data-ttu-id="4c120-133">**[Azure Logic Apps][logic-apps]** は、ワークフローをトリガーするために使用されます。</span><span class="sxs-lookup"><span data-stu-id="4c120-133">**[Azure Logic Apps][logic-apps]** is used to trigger the workflow.</span></span> <span data-ttu-id="4c120-134">Logic Apps は、コンテナーに BLOB が追加されたことを検出すると、Azure Machine Learning Pipelines をトリガーします。</span><span class="sxs-lookup"><span data-stu-id="4c120-134">When the Logic App detects that a blob has been added to the container, it triggers the Azure Machine Learning Pipeline.</span></span> <span data-ttu-id="4c120-135">Logic Apps は、BLOB ストレージに対する変更を検出する簡単な方法であり、トリガーを変更するための簡単なプロセスを備えているため、この参照アーキテクチャに非常に適しています。</span><span class="sxs-lookup"><span data-stu-id="4c120-135">Logic Apps is a good fit for this reference architecture because it's an easy way to detect changes to blob storage and provides an easy process for changing the trigger.</span></span>

### <a name="preprocessing-and-postprocessing-our-data"></a><span data-ttu-id="4c120-136">データの前処理と後処理</span><span class="sxs-lookup"><span data-stu-id="4c120-136">Preprocessing and postprocessing our data</span></span>

<span data-ttu-id="4c120-137">この参照アーキテクチャでは、木の中にいるオランウータンの動画映像を使用します。</span><span class="sxs-lookup"><span data-stu-id="4c120-137">This reference architecture uses video footage of an orangutan in a tree.</span></span> <span data-ttu-id="4c120-138">映像は [こちら][source-video]からダウンロードできます。</span><span class="sxs-lookup"><span data-stu-id="4c120-138">You can download the footage from [here][source-video].</span></span>

1. <span data-ttu-id="4c120-139">[FFmpeg][ffmpeg] を使用して動画映像からオーディオ ファイルを抽出し、後で出力動画にオーディオ ファイルを合成できるようにします。</span><span class="sxs-lookup"><span data-stu-id="4c120-139">Use [FFmpeg][ffmpeg] to extract the audio file from the video footage, so that the audio file can be stitched back into the output video later.</span></span>
1. <span data-ttu-id="4c120-140">FFmpeg を使用して、動画を個々のフレームに分割します。</span><span class="sxs-lookup"><span data-stu-id="4c120-140">Use FFmpeg to break the video into individual frames.</span></span> <span data-ttu-id="4c120-141">フレームは、並列で個別に処理されます。</span><span class="sxs-lookup"><span data-stu-id="4c120-141">The frames will be processed independently, in parallel.</span></span>
1. <span data-ttu-id="4c120-142">この時点で、ニューラル スタイルの転送を個々のフレームに並列で適用できます。</span><span class="sxs-lookup"><span data-stu-id="4c120-142">At this point, we can apply neural style transfer to each individual frame in parallel.</span></span>
1. <span data-ttu-id="4c120-143">各フレームの処理が完了したら、FFmpeg を使用して、フレームを元のように再合成する必要があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-143">One each frame has been processed, we need to use FFmpeg to restitch the frames back together.</span></span>
1. <span data-ttu-id="4c120-144">最後に、合成された映像にオーディオ ファイルを再合成します。</span><span class="sxs-lookup"><span data-stu-id="4c120-144">Finally we reattach the audio file to the restitched footage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="4c120-145">パフォーマンスに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="4c120-145">Performance considerations</span></span>

### <a name="gpu-vs-cpu"></a><span data-ttu-id="4c120-146">GPU と CPU</span><span class="sxs-lookup"><span data-stu-id="4c120-146">GPU vs CPU</span></span>

<span data-ttu-id="4c120-147">ディープ ラーニング ワークロードでは、同等のパフォーマンスを得るためには非常に大規模な CPU クラスターが必要になるため、一般に、CPU より GPU の方がかなり優れています。</span><span class="sxs-lookup"><span data-stu-id="4c120-147">For deep learning workloads, GPUs will generally out-perform CPUs by a considerable amount, to the extent that a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span> <span data-ttu-id="4c120-148">このアーキテクチャでは CPU のみを使用することもできますが、GPU の方が優れたコスト/パフォーマンス プロファイルを提供します。</span><span class="sxs-lookup"><span data-stu-id="4c120-148">While it's an option to use only CPUs in this architecture, GPUs will provide a much better cost/performance profile.</span></span> <span data-ttu-id="4c120-149">GPU 最適化 VM の最新の [NCv3 シリーズ]vm-sizes-gpu を使用することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="4c120-149">We recommend using the latest [NCv3 series]vm-sizes-gpu of GPU optimized VMs.</span></span>

<span data-ttu-id="4c120-150">すべてのリージョンで、GPU は既定では有効になっていません。</span><span class="sxs-lookup"><span data-stu-id="4c120-150">GPUs are not enabled by default in all regions.</span></span> <span data-ttu-id="4c120-151">GPU が有効になっているリージョンを選択してください。</span><span class="sxs-lookup"><span data-stu-id="4c120-151">Make sure to select a region with GPUs enabled.</span></span> <span data-ttu-id="4c120-152">さらに、サブスクリプションの既定のクォータでは、GPU 最適化 VM のコア数は 0 です。</span><span class="sxs-lookup"><span data-stu-id="4c120-152">In addition, subscriptions have a default quota of zero cores for GPU-optimized VMs.</span></span> <span data-ttu-id="4c120-153">サポート要求を開くことで、このクォータを増やすことができます。</span><span class="sxs-lookup"><span data-stu-id="4c120-153">You can raise this quota by opening a support request.</span></span> <span data-ttu-id="4c120-154">ワークロードを実行するための十分なクォータがサブスクリプションにあることを確認してください。</span><span class="sxs-lookup"><span data-stu-id="4c120-154">Make sure that your subscription has enough quota to run your workload.</span></span>

### <a name="parallelizing-across-vms-vs-cores"></a><span data-ttu-id="4c120-155">VM とコアの間の並列化</span><span class="sxs-lookup"><span data-stu-id="4c120-155">Parallelizing across VMs vs cores</span></span>

<span data-ttu-id="4c120-156">スタイル転送プロセスをバッチ ジョブとして実行するとき、主に GPU 上で実行されるジョブは、VM 間で並列化する必要があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-156">When running a style transfer process as a batch job, the jobs that run primarily on GPUs will have to be parallelized across VMs.</span></span> <span data-ttu-id="4c120-157">2 つの方法が可能であり、単一の GPU を備えた VM を使用して大規模なクラスターを作成するか、または多くの GPU を備えた VM を使用して小規模なクラスターを作成することができます。</span><span class="sxs-lookup"><span data-stu-id="4c120-157">Two approaches are possible: You can create a larger cluster using VMs that have a single GPU, or create a smaller cluster using VMs with many GPUs.</span></span>

<span data-ttu-id="4c120-158">このワークロードでは、これら 2 つのオプションのパフォーマンスは同等です。</span><span class="sxs-lookup"><span data-stu-id="4c120-158">For this workload, these two options will have comparable performance.</span></span> <span data-ttu-id="4c120-159">VM あたりの GPU が多い少数の VM を使用すると、データ移動を削減するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="4c120-159">Using fewer VMs with more GPUs per VM can help to reduce data movement.</span></span> <span data-ttu-id="4c120-160">ただし、このワークロードではジョブごとのデータ量がそれほど多くないので、BLOB ストレージによって大きく制限されることはありません。</span><span class="sxs-lookup"><span data-stu-id="4c120-160">However, the data volume per job for this workload is not very big, so you won't observe much throttling by blob storage.</span></span>

### <a name="mpi-step"></a><span data-ttu-id="4c120-161">MPI のステップ</span><span class="sxs-lookup"><span data-stu-id="4c120-161">MPI step</span></span> 

<span data-ttu-id="4c120-162">Azure Machine Learning でパイプラインを作成する場合、並列計算を実行するために使用されるステップの 1 つが MPI のステップです。</span><span class="sxs-lookup"><span data-stu-id="4c120-162">When creating the pipeline in Azure Machine Learning, one of the steps used to perform parallel computation is the MPI step.</span></span> <span data-ttu-id="4c120-163">MPI のステップは、使用可能なノード間でデータを均等に分割するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="4c120-163">The MPI step will help split the data evenly across the available nodes.</span></span> <span data-ttu-id="4c120-164">MPI のステップは、要求されたすべてのノードの準備が整うまでは実行されません。</span><span class="sxs-lookup"><span data-stu-id="4c120-164">The MPI step will not executed until all the requested nodes are ready.</span></span> <span data-ttu-id="4c120-165">1 つのノードが失敗したり、割り込まれたりした場合 (それが優先順位の低い仮想マシンであっても)、MPI のステップを再実行する必要があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-165">Should one node fail or get pre-empted (if it is a low-priority virtual machine), the MPI step will have to be re-run.</span></span> 

## <a name="security-considerations"></a><span data-ttu-id="4c120-166">セキュリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="4c120-166">Security considerations</span></span>

### <a name="restricting-access-to-azure-blob-storage"></a><span data-ttu-id="4c120-167">Azure Blob Storage へのアクセスの制限</span><span class="sxs-lookup"><span data-stu-id="4c120-167">Restricting access to Azure blob storage</span></span>

<span data-ttu-id="4c120-168">この参照アーキテクチャでは、Azure Blob Storage が保護する必要のあるメイン ストレージ コンポーネントです。</span><span class="sxs-lookup"><span data-stu-id="4c120-168">In this reference architecture, Azure blob storage is the main storage component that needs to be protected.</span></span> <span data-ttu-id="4c120-169">GitHub リポジトリで示されているベースライン展開では、ストレージ アカウント キーを使用して BLOB ストレージにアクセスしています。</span><span class="sxs-lookup"><span data-stu-id="4c120-169">The baseline deployment shown in the GitHub repo uses storage account keys to access the blob storage.</span></span> <span data-ttu-id="4c120-170">さらに制御と保護を強化するには、共有アクセス署名 (SAS) を代わりに使用することを検討します。</span><span class="sxs-lookup"><span data-stu-id="4c120-170">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="4c120-171">これは、ストレージ内のオブジェクトへの制限されたアクセスを付与し、アカウント キーをハード コーディングしたり、それをプレーンテキストで保存したりする必要はありません。</span><span class="sxs-lookup"><span data-stu-id="4c120-171">This grants limited access to objects in storage, without needing to hard code the account keys or save them in plaintext.</span></span> <span data-ttu-id="4c120-172">ロジック アプリのデザイナー インターフェイスの内部ではアカウント キーがプレーンテキストで表示されるので、このアプローチは特に便利です。</span><span class="sxs-lookup"><span data-stu-id="4c120-172">This approach is especially useful because account keys are visible in plaintext inside of Logic App's designer interface.</span></span> <span data-ttu-id="4c120-173">SAS を使用すると、ストレージ アカウントに適切なガバナンスがあること、およびアクセス権がそれを必要とするユーザーだけに付与されることを保証するのにも役立ちます。</span><span class="sxs-lookup"><span data-stu-id="4c120-173">Using an SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="4c120-174">ストレージ キーはワークロードのすべての入出力データに対するフル アクセス権を与えるため、データの機密性がさらに高いシナリオでは、すべてのストレージ キーが保護されるようにします。</span><span class="sxs-lookup"><span data-stu-id="4c120-174">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="data-encryption-and-data-movement"></a><span data-ttu-id="4c120-175">データの暗号化とデータの移動</span><span class="sxs-lookup"><span data-stu-id="4c120-175">Data encryption and data movement</span></span>

<span data-ttu-id="4c120-176">この参照アーキテクチャでは、バッチ スコアリング プロセスの例として、スタイルの転送を使用しています。</span><span class="sxs-lookup"><span data-stu-id="4c120-176">This reference architecture uses style transfer as an example of a batch scoring process.</span></span> <span data-ttu-id="4c120-177">データの機密性がさらに高いシナリオでは、ストレージに保存されているときのデータを暗号化する必要があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-177">For more data-sensitive scenarios, the data in storage should be encrypted at rest.</span></span> <span data-ttu-id="4c120-178">データがある場所から次の場所に移動されるたびに、SSL を使用してデータ転送をセキュリティ保護します。</span><span class="sxs-lookup"><span data-stu-id="4c120-178">Each time data is moved from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="4c120-179">詳しくは、「[Azure Storage セキュリティ ガイド][storage-security]」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="4c120-179">For more information, see [Azure Storage security guide][storage-security].</span></span>

### <a name="securing-your-computation-in-a-virtual-network"></a><span data-ttu-id="4c120-180">仮想ネットワーク内での計算のセキュリティ保護</span><span class="sxs-lookup"><span data-stu-id="4c120-180">Securing your computation in a virtual network</span></span>

<span data-ttu-id="4c120-181">Machine Learning コンピューティング クラスターをデプロイするときは、[仮想ネットワーク][virtual-network]のサブネット内にプロビジョニングされるようにクラスターを構成できます。</span><span class="sxs-lookup"><span data-stu-id="4c120-181">When deploying your Machine Learning compute cluster, you can configure your cluster to be provisioned inside a subnet of a [virtual network][virtual-network].</span></span> <span data-ttu-id="4c120-182">これにより、クラスター内のコンピューティング ノードは、他の仮想マシンと安全に通信できます。</span><span class="sxs-lookup"><span data-stu-id="4c120-182">This allows the compute nodes in the cluster to communicate securely with other virtual machines.</span></span> 

### <a name="protecting-against-malicious-activity"></a><span data-ttu-id="4c120-183">悪意のあるアクティビティからの保護</span><span class="sxs-lookup"><span data-stu-id="4c120-183">Protecting against malicious activity</span></span>

<span data-ttu-id="4c120-184">複数のユーザーがいるシナリオでは、機密データが悪意のあるアクティビティに対して保護されるようにします。</span><span class="sxs-lookup"><span data-stu-id="4c120-184">In scenarios where there are multiple users, make sure that sensitive data is protected against malicious activity.</span></span> <span data-ttu-id="4c120-185">この展開にアクセスして入力データをカスタマイズすることを他のユーザーに許可する場合は、次の注意事項と考慮事項に留意します。</span><span class="sxs-lookup"><span data-stu-id="4c120-185">If other users are given access to this deployment to customize the input data, take note of the following precautions and considerations:</span></span>

- <span data-ttu-id="4c120-186">RBAC を使用して、ユーザーのアクセスを必要なリソースのみに制限します。</span><span class="sxs-lookup"><span data-stu-id="4c120-186">Use RBAC to limit users' access to only the resources they need.</span></span>
- <span data-ttu-id="4c120-187">2 つのストレージ アカウントを個別にプロビジョニングします。</span><span class="sxs-lookup"><span data-stu-id="4c120-187">Provision two separate storage accounts.</span></span> <span data-ttu-id="4c120-188">1 つのアカウントで、入力と出力のデータを格納します。</span><span class="sxs-lookup"><span data-stu-id="4c120-188">Store input and output data in the first account.</span></span> <span data-ttu-id="4c120-189">外部ユーザーにはこのアカウントへのアクセスを許可できます。</span><span class="sxs-lookup"><span data-stu-id="4c120-189">External users can be given access to this account.</span></span> <span data-ttu-id="4c120-190">もう 1 つのアカウントには、実行可能なスクリプトと出力ログ ファイルを格納します。</span><span class="sxs-lookup"><span data-stu-id="4c120-190">Store executable scripts and output log files in the other account.</span></span> <span data-ttu-id="4c120-191">外部ユーザーはこのアカウントにアクセスできないようにします。</span><span class="sxs-lookup"><span data-stu-id="4c120-191">External users should not have access to this account.</span></span> <span data-ttu-id="4c120-192">このようにすると、外部ユーザーは実行可能ファイルを変更 (して悪意のあるコードを挿入) することができず、機密情報が保持されている可能性があるログ ファイルにアクセスできません。</span><span class="sxs-lookup"><span data-stu-id="4c120-192">This will ensure that external users cannot modify any executable files (to inject malicious code), and don't have access to logfiles, which could hold sensitive information.</span></span>
- <span data-ttu-id="4c120-193">悪意のあるユーザーは、ジョブ キューに対して DDOS を行ったり、不正な形式の有害なメッセージをジョブ キューに挿入したりして、システムをロックさせたりデキュー エラーを発生させたりする可能性があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-193">Malicious users can DDOS the job queue or inject malformed poison messages in the job queue, causing the system to lock up or causing dequeuing errors.</span></span>

## <a name="monitoring-and-logging"></a><span data-ttu-id="4c120-194">監視およびログ記録</span><span class="sxs-lookup"><span data-stu-id="4c120-194">Monitoring and logging</span></span>

### <a name="monitoring-batch-jobs"></a><span data-ttu-id="4c120-195">Batch ジョブの監視</span><span class="sxs-lookup"><span data-stu-id="4c120-195">Monitoring Batch jobs</span></span>

<span data-ttu-id="4c120-196">ジョブの実行中は、進行状況を監視し、想定どおりに動作していることを確認することが重要です。</span><span class="sxs-lookup"><span data-stu-id="4c120-196">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="4c120-197">ただし、アクティブなノードのクラスター全体を監視するのは困難な場合があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-197">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="4c120-198">クラスターの全体的な状態を把握するには、Azure portal の [Machine Learning] ブレードに移動して、クラスター内のノードの状態を調べます。</span><span class="sxs-lookup"><span data-stu-id="4c120-198">To get a sense of the overall state of the cluster, go to the Machine Learning blade of the Azure Portal to inspect the state of the nodes in the cluster.</span></span> <span data-ttu-id="4c120-199">ノードが非アクティブになった場合、またはジョブが失敗した場合は、エラー ログが Blob Storage に保存され、Azure portal からアクセスすることもできます。</span><span class="sxs-lookup"><span data-stu-id="4c120-199">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Azure Portal.</span></span>

<span data-ttu-id="4c120-200">ログを Application Insights に接続することで、または別のプロセスを実行してクラスターとそのジョブの状態をポーリングすることで、監視をさらに強化できます。</span><span class="sxs-lookup"><span data-stu-id="4c120-200">Monitoring can be further enriched by connecting logs to Application Insights or by running separate processes to poll for the state of the cluster and its jobs.</span></span>

### <a name="logging-with-azure-machine-learning"></a><span data-ttu-id="4c120-201">Azure Machine Learning によるログ記録</span><span class="sxs-lookup"><span data-stu-id="4c120-201">Logging with Azure Machine Learning</span></span>

<span data-ttu-id="4c120-202">Azure Machine Learning は、関連付けられている Blob ストレージ アカウントに、すべての stdout/stderr を自動的に記録します。</span><span class="sxs-lookup"><span data-stu-id="4c120-202">Azure Machine Learing will automatically log all stdout/stderr to the associate blob storage account.</span></span> <span data-ttu-id="4c120-203">特に指定しない場合、Azure Machine Learning ワークスペースによって、自動的にストレージ アカウントがプロビジョニングされ、そこにログがダンプされます。</span><span class="sxs-lookup"><span data-stu-id="4c120-203">Unless otherwise specified, your Azure Machine Learning Workspace will automatically provision a storage account and dump your logs into it.</span></span> <span data-ttu-id="4c120-204">Storage Explorer などのストレージ ナビゲーション ツールを使用することもできます。これにより、ログ ファイル間を移動するエクスペリエンスがはるかに簡単になります。</span><span class="sxs-lookup"><span data-stu-id="4c120-204">You can also use a storage navigation tool such as Storage Explorer which will provide a much easier experience for navigating log files.</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="4c120-205">コストに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="4c120-205">Cost considerations</span></span>

<span data-ttu-id="4c120-206">コストの点では、この参照アーキテクチャで使用されているコンピューティング リソースは、ストレージおよびスケジュール コンポーネントより、はるかに大きい部分を占めます。</span><span class="sxs-lookup"><span data-stu-id="4c120-206">Compared to the storage and scheduling components, the compute resources used in this reference architecture by far dominate in terms of costs.</span></span> <span data-ttu-id="4c120-207">主要な課題の 1 つは、GPU 対応マシンのクラスター全体に作業を効果的に並列化することです。</span><span class="sxs-lookup"><span data-stu-id="4c120-207">One of the main challenges is effectively parallelizing the work across a cluster of GPU-enabled machines.</span></span>

<span data-ttu-id="4c120-208">Machine Learning コンピューティング クラスターのサイズは、キュー内のジョブに応じて、自動的にスケールアップおよびスケールダウンできます。</span><span class="sxs-lookup"><span data-stu-id="4c120-208">The Machine Learning Compute cluster size can automatically scale up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="4c120-209">プログラムで最小ノード数と最大ノード数を設定することで、自動スケーリングを有効にできます。</span><span class="sxs-lookup"><span data-stu-id="4c120-209">You can enable auto-scale programmatically by setting the minimum and maximum nodes.</span></span>

<span data-ttu-id="4c120-210">即時処理を必要としない作業の場合は、既定の状態 (最小) が、ノード数 0 個のクラスターになるように、自動スケーリングを構成します。</span><span class="sxs-lookup"><span data-stu-id="4c120-210">For work that doesn't require immediate processing, configure auto-scale so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="4c120-211">この構成では、クラスターは 0 個のノードで開始し、キュー内でジョブが検出されたときのみスケールアップします。</span><span class="sxs-lookup"><span data-stu-id="4c120-211">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="4c120-212">バッチ スコアリング プロセスが 1 日に数回以下しか発生しない場合は、この設定により大幅なコスト削減を実現できます。</span><span class="sxs-lookup"><span data-stu-id="4c120-212">If the batch scoring process only happens a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="4c120-213">非常に短い間隔で発生するバッチ ジョブでは、自動スケールが適切ではない場合があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-213">Auto-scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="4c120-214">クラスターの起動と停止に要する時間にもコストがかかるので、前のジョブの終了後ほんの数分でバッチ ワークロードが開始する場合は、ジョブ間もクラスターを実行したままにする方がコスト効率がよくなる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="4c120-214">The time that it takes for a cluster to spin up and spin down also incur a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span>

<span data-ttu-id="4c120-215">Machine Learning コンピューティングでは、低優先度の仮想マシンもサポートしています。</span><span class="sxs-lookup"><span data-stu-id="4c120-215">Machine Learning Compute also supports low-priority virtual machines.</span></span> <span data-ttu-id="4c120-216">これにより、割引料金の仮想マシンで計算処理を実行できます。ただし、これらの仮想マシンでは割り込みが発生する可能性が常にあることに注意が必要です。</span><span class="sxs-lookup"><span data-stu-id="4c120-216">This allows you to run your computation on discounted virtual machines, with the caveat that they may be pre-empted at any time.</span></span> <span data-ttu-id="4c120-217">低優先度の仮想マシンは、重要度の低いバッチ スコアリング ワークロードに最適です。</span><span class="sxs-lookup"><span data-stu-id="4c120-217">Low-priority virtual machines are ideal for non-critical batch scoring workloads.</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="4c120-218">ソリューションのデプロイ方法</span><span class="sxs-lookup"><span data-stu-id="4c120-218">Deploy the solution</span></span>

<span data-ttu-id="4c120-219">この参照アーキテクチャを展開するには、[GitHub リポジトリ][deployment]で説明されている手順に従ってください。</span><span class="sxs-lookup"><span data-stu-id="4c120-219">To deploy this reference architecture, follow the steps described in the [GitHub repo][deployment].</span></span>

> [!NOTE]
> <span data-ttu-id="4c120-220">また、Azure Kubernetes Service を使用して、ディープ ラーニング モデル用にバッチ スコアリング アーキテクチャをデプロイすることもできます。</span><span class="sxs-lookup"><span data-stu-id="4c120-220">You can also deploy a batch scoring architecture for deep learning models using the Azure Kubernetes Service.</span></span> <span data-ttu-id="4c120-221">この [Github リポジトリ][deployment2]で説明されている手順に従ってください。</span><span class="sxs-lookup"><span data-stu-id="4c120-221">Follow the steps described in this [Github repo][deployment2].</span></span>


<!-- links -->

[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azcopy]: /azure/storage/common/storage-use-azcopy-linux
[blob-storage]: /azure/storage/blobs/storage-blobs-introduction
[container-instances]: /azure/container-instances/
[container-registry]: /azure/container-registry/
[deployment]: https://github.com/Azure/Batch-Scoring-Deep-Learning-Models-With-AML
[deployment2]: https://github.com/Azure/Batch-Scoring-Deep-Learning-Models-With-AKS
[ffmpeg]: https://www.ffmpeg.org/
[image-style-transfer]: https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf
[logic-apps]: /azure/logic-apps/
[source-video]: https://happypathspublic.blob.core.windows.net/videos/orangutan.mp4
[storage-security]: /azure/storage/common/storage-security-guide
[vm-sizes-gpu]: /azure/virtual-machines/windows/sizes-gpu
[virtual-network]: /azure/machine-learning/service/how-to-enable-virtual-network
