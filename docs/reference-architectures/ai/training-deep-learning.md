---
title: Azure でのディープ ラーニング モデルの分散トレーニング
description: この参照アーキテクチャでは、Azure Batch AI を使用して、GPU 対応 VM のクラスター間でディープ ラーニング モデルの分散トレーニングを実施する方法を示します。
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 800defeb851f5a31dc730038c3699e1a3d54b923
ms.sourcegitcommit: d5ea427c25f9f7799cc859b99f328739ca2d8c1c
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/15/2019
ms.locfileid: "54307783"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a><span data-ttu-id="313fd-103">Azure でのディープ ラーニング モデルの分散トレーニング</span><span class="sxs-lookup"><span data-stu-id="313fd-103">Distributed training of deep learning models on Azure</span></span>

<span data-ttu-id="313fd-104">この参照アーキテクチャでは、GPU 対応 VM のクラスター間でディープ ラーニング モデルの分散トレーニングを実施する方法を示します。</span><span class="sxs-lookup"><span data-stu-id="313fd-104">This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span> <span data-ttu-id="313fd-105">シナリオは画像の分類ですが、ソリューションは、セグメント化やオブジェクト検出など、その他のディープ ラーニング シナリオに一般化することが可能です。</span><span class="sxs-lookup"><span data-stu-id="313fd-105">The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</span></span>

<span data-ttu-id="313fd-106">このアーキテクチャのリファレンス実装は、[GitHub][github] で入手できます。</span><span class="sxs-lookup"><span data-stu-id="313fd-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![分散型のディープ ラーニングのアーキテクチャ][0]

<span data-ttu-id="313fd-108">**シナリオ**: イメージの分類は、コンピューター ビジョンにおいて広く適用されている技法であり、多くの場合、畳み込みニューラル ネットワーク (CNN) をトレーニングすることで対応されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-108">**Scenario**: Image classification is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN).</span></span> <span data-ttu-id="313fd-109">大規模なデータセットを備える特に大きなモデルでは、単一の GPU に対するトレーニング プロセスに数週間または数か月かかる場合があります。</span><span class="sxs-lookup"><span data-stu-id="313fd-109">For particularly large models with large datasets, the training process can take weeks or months on a single GPU.</span></span> <span data-ttu-id="313fd-110">状況によっては、モデルが非常に大きいために、GPU 上に妥当なバッチ サイズを適合させることができない場合もあります。</span><span class="sxs-lookup"><span data-stu-id="313fd-110">In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU.</span></span> <span data-ttu-id="313fd-111">このような状況に分散トレーニングを使用すると、トレーニング時間を短縮できます。</span><span class="sxs-lookup"><span data-stu-id="313fd-111">Using distributed training in these situations can shorten the training time.</span></span>

<span data-ttu-id="313fd-112">今回の特定のシナリオでは、[Imagenet データセット][imagenet]および合成データに対して、[Horovod][horovod] を使用して [ResNet50 CNN モデル][resnet]がトレーニングされます。</span><span class="sxs-lookup"><span data-stu-id="313fd-112">In this specific scenario, a [ResNet50 CNN model][resnet] is trained using [Horovod][horovod] on the [Imagenet dataset][imagenet] and on synthetic data.</span></span> <span data-ttu-id="313fd-113">リファレンス実装では、最も一般的な 3 つのディープ ラーニング フレームワークであるTensorFlow、Keras、および PyTorch を使用して、このタスクを完了する方法を示しています。</span><span class="sxs-lookup"><span data-stu-id="313fd-113">The reference implementation shows how to accomplish this task using three of the most popular deep learning frameworks: TensorFlow, Keras, and PyTorch.</span></span>

<span data-ttu-id="313fd-114">分散型の方式でディープ ラーニング モデルをトレーニングするには、同期または非同期の更新に基づくデータ並列およびモデル並列の手法を含め、複数の方法があります。</span><span class="sxs-lookup"><span data-stu-id="313fd-114">There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates.</span></span> <span data-ttu-id="313fd-115">現在、最も一般的なシナリオは、同期更新によるデータ並列です。</span><span class="sxs-lookup"><span data-stu-id="313fd-115">Currently the most common scenario is data parallel with synchronous updates.</span></span> <span data-ttu-id="313fd-116">この手法は、実装が最も簡単であり、ほとんどのユース ケースに対応します。</span><span class="sxs-lookup"><span data-stu-id="313fd-116">This approach is the easiest to implement and is sufficient for most use cases.</span></span>

<span data-ttu-id="313fd-117">同期更新によるデータ並列の分散トレーニングでは、モデルは *n* 個のハードウェア デバイスにわたってレプリケートされます。</span><span class="sxs-lookup"><span data-stu-id="313fd-117">In data-parallel distributed training with synchronous updates, the model is replicated across *n* hardware devices.</span></span> <span data-ttu-id="313fd-118">トレーニング サンプルのミニバッチは、*n* 個のマイクロ バッチに分割されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-118">A mini-batch of training samples is divided into *n* micro-batches.</span></span> <span data-ttu-id="313fd-119">各デバイスは、1 つのマイクロバッチに対して順方向および逆方向の受け渡しを実行します。</span><span class="sxs-lookup"><span data-stu-id="313fd-119">Each device performs the forward and backward passes for a micro-batch.</span></span> <span data-ttu-id="313fd-120">デバイスはプロセスを終了するきに、更新内容を他のデバイスと共有します。</span><span class="sxs-lookup"><span data-stu-id="313fd-120">When a device finishes the process, it shares the updates with the other devices.</span></span> <span data-ttu-id="313fd-121">これらの値は、ミニバッチ全体の更新後の重みを計算するために使用され、重みはモデル間で同期されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-121">These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models.</span></span> <span data-ttu-id="313fd-122">このシナリオについては、[GitHub][github] リポジトリの中で説明されています。</span><span class="sxs-lookup"><span data-stu-id="313fd-122">This scenario is covered in the [GitHub][github] repository.</span></span>

![データ並列の分散トレーニング][1]

<span data-ttu-id="313fd-124">このアーキテクチャは、モデル並列の非同期更新にも使用できます。</span><span class="sxs-lookup"><span data-stu-id="313fd-124">This architecture can also be used for model-parallel and asynchronous updates.</span></span> <span data-ttu-id="313fd-125">モデル並列の分散トレーニングでは、*n* 個のハードウェア デバイスにわたってモデルが分割され、各デバイスがモデルの一部を保持している状態になります。</span><span class="sxs-lookup"><span data-stu-id="313fd-125">In model-parallel distributed training, the model is divided across *n* hardware devices, with each device holding a part of the model.</span></span> <span data-ttu-id="313fd-126">最もシンプルな実装では、デバイスごとにネットワークの 1 つの層を保持することができ、順方向および逆方向の受け渡しの中で、デバイス間に情報が渡されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-126">In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass.</span></span> <span data-ttu-id="313fd-127">比較的規模の大きいニューラル ネットワークの場合、この方法によるトレーニングは可能ですが、デバイスは順方向または逆方向の受け渡しを互いに完了するまで常に待機するため、パフォーマンス コストがかかります。</span><span class="sxs-lookup"><span data-stu-id="313fd-127">Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass.</span></span> <span data-ttu-id="313fd-128">一部の高度な技法では、合成勾配を使用して、この問題の部分的な軽減を試みています。</span><span class="sxs-lookup"><span data-stu-id="313fd-128">Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</span></span>

<span data-ttu-id="313fd-129">トレーニングの手順は次のとおりです。</span><span class="sxs-lookup"><span data-stu-id="313fd-129">The steps for training are:</span></span>

1. <span data-ttu-id="313fd-130">クラスター上で実行されるスクリプトを作成し、お使いのモデルをトレーニングしてから、スクリプトをファイル ストレージに転送する。</span><span class="sxs-lookup"><span data-stu-id="313fd-130">Create scripts that will run on the cluster and train your model, then transfer them to file storage.</span></span>

1. <span data-ttu-id="313fd-131">Blob ストレージにデータを書き込む。</span><span class="sxs-lookup"><span data-stu-id="313fd-131">Write the data to Blob Storage.</span></span>

1. <span data-ttu-id="313fd-132">Batch AI ファイル サーバーを作成して、Blob ストレージからこのサーバーにデータをダウンロードする。</span><span class="sxs-lookup"><span data-stu-id="313fd-132">Create a Batch AI file server and download the data from Blob Storage onto it.</span></span>

1. <span data-ttu-id="313fd-133">各ディープ ラーニング フレームワーク用の Docker コンテナーを作成し、コンテナー レジストリ (Docker Hub) に転送する。</span><span class="sxs-lookup"><span data-stu-id="313fd-133">Create the Docker containers for each deep learning framework and transfer them to a container registry (Docker Hub).</span></span>

1. <span data-ttu-id="313fd-134">Batch AI ファイル サーバーもマウントする Batch AI プールを作成する。</span><span class="sxs-lookup"><span data-stu-id="313fd-134">Create a Batch AI pool that also mounts the Batch AI file server.</span></span>

1. <span data-ttu-id="313fd-135">ジョブを送信する。</span><span class="sxs-lookup"><span data-stu-id="313fd-135">Submit jobs.</span></span> <span data-ttu-id="313fd-136">それぞれが、適切な Docker イメージとスクリプトをプルします。</span><span class="sxs-lookup"><span data-stu-id="313fd-136">Each pulls in the appropriate Docker image and scripts.</span></span>

1. <span data-ttu-id="313fd-137">ジョブが完了した後に、すべての結果を Files ストレージに書き込む。</span><span class="sxs-lookup"><span data-stu-id="313fd-137">Once the job is completed, write all the results to Files storage.</span></span>

## <a name="architecture"></a><span data-ttu-id="313fd-138">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="313fd-138">Architecture</span></span>

<span data-ttu-id="313fd-139">このアーキテクチャは、次のコンポーネントで構成されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-139">This architecture consists of the following components.</span></span>

<span data-ttu-id="313fd-140">**[Azure Batch AI][batch-ai]** は、ニーズに応じてリソースをスケールアップおよびスケールアウトすることで、このアーキテクチャにおける中心的な役割を担います。</span><span class="sxs-lookup"><span data-stu-id="313fd-140">**[Azure Batch AI][batch-ai]** plays the central role in this architecture by scaling resources up and down according to need.</span></span> <span data-ttu-id="313fd-141">Batch AI は、VM のクラスターのプロビジョニングおよび管理、ジョブのスケジュール設定、結果の収集、リソースのスケーリング、エラーの処理、および適切なストレージの作成に利用できるサービスです。</span><span class="sxs-lookup"><span data-stu-id="313fd-141">Batch AI is a service that helps provision and manage clusters of VMs, schedule jobs, gather results, scale resources, handle failures, and create appropriate storage.</span></span> <span data-ttu-id="313fd-142">ディープ ラーニング ワークロードでの GPU 対応 VM をサポートしています。</span><span class="sxs-lookup"><span data-stu-id="313fd-142">It supports GPU-enabled VMs for deep learning workloads.</span></span> <span data-ttu-id="313fd-143">Batch AI には、Python SDK およびコマンド ライン インターフェイス (CLI) が利用可能です。</span><span class="sxs-lookup"><span data-stu-id="313fd-143">A Python SDK and a command-line interface (CLI) are available for Batch AI.</span></span>

> [!NOTE]
> <span data-ttu-id="313fd-144">Azure Batch AI サービスは 2019 年 3 月に終了する予定であり、このサービスの大規模トレーニングとスコアリングの機能は現在、[Azure Machine Learning Service][amls] において利用可能になっています。</span><span class="sxs-lookup"><span data-stu-id="313fd-144">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="313fd-145">この参照アーキテクチャは近日中に Machine Learning を使用するように改定されます。Machine Learning では、[Azure Machine Learning コンピューティング][aml-compute]という、機械学習モデルのトレーニング、デプロイ、およびスコアリングのためのマネージド コンピューティング先を提供します。</span><span class="sxs-lookup"><span data-stu-id="313fd-145">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

<span data-ttu-id="313fd-146">**[Blob ストレージ][azure-blob]** は、データをステージングするために使用されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-146">**[Blob storage][azure-blob]** is used to stage the data.</span></span> <span data-ttu-id="313fd-147">このデータはトレーニング中に、Batch AI ファイル サーバーにダウンロードされます。</span><span class="sxs-lookup"><span data-stu-id="313fd-147">This data is downloaded to a Batch AI file server during training.</span></span>

<span data-ttu-id="313fd-148">**[Azure Files][files]** は、スクリプト、ログ、およびトレーニングからの最終結果を格納するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-148">**[Azure Files][files]** is used to store the scripts, logs, and the final results from the training.</span></span> <span data-ttu-id="313fd-149">ファイル ストレージは、ログとスクリプトの格納に適していますが、パフォーマンスは Blob ストレージほどには優れていないので、データ量の多いタスクには使用できません。</span><span class="sxs-lookup"><span data-stu-id="313fd-149">File storage works well for storing logs and scripts, but is not as performant as Blob Storage, so it shouldn't be used for data-intensive tasks.</span></span>

<span data-ttu-id="313fd-150">**[Batch AI ファイル サーバー][batch-ai-files]** は、トレーニング データを格納するために、このアーキテクチャ内で使用される単一ノードの NFS 共有です。</span><span class="sxs-lookup"><span data-stu-id="313fd-150">**[Batch AI file server][batch-ai-files]** is a single-node NFS share used in this architecture to store the training data.</span></span> <span data-ttu-id="313fd-151">Batch AI では NFS 共有を作成して、クラスター上にマウントします。</span><span class="sxs-lookup"><span data-stu-id="313fd-151">Batch AI creates an NFS share and mounts it on the cluster.</span></span> <span data-ttu-id="313fd-152">Batch AI ファイル サーバーは、必要なスループットでクラスターにデータを提供するためのお勧めの方法です。</span><span class="sxs-lookup"><span data-stu-id="313fd-152">Batch AI file servers are the recommended way to serve data to the cluster with the necessary throughput.</span></span>

<span data-ttu-id="313fd-153">**[Docker Hub][docker]** は、Batch AI がトレーニングの実行に利用する Docker イメージを格納するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="313fd-153">**[Docker Hub][docker]** is used to store the Docker image that Batch AI uses to run the training.</span></span> <span data-ttu-id="313fd-154">Docker Hub は、使いやすく、Docker ユーザーに対する既定のイメージ リポジトリであるため、このアーキテクチャに選択されました。</span><span class="sxs-lookup"><span data-stu-id="313fd-154">Docker Hub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="313fd-155">[Azure Container Registry][acr] を使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="313fd-155">[Azure Container Registry][acr] can also be used.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="313fd-156">パフォーマンスに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="313fd-156">Performance considerations</span></span>

<span data-ttu-id="313fd-157">Azure では、ディープ ラーニング モデルのトレーニングに適した 4 つの [GPU 対応 VM の種類][gpu]を提供しています。</span><span class="sxs-lookup"><span data-stu-id="313fd-157">Azure provides four [GPU-enabled VM types][gpu] suitable for training deep learning models.</span></span> <span data-ttu-id="313fd-158">種類は次に示すとおりで、価格および速度が低いものから高いものまであります。</span><span class="sxs-lookup"><span data-stu-id="313fd-158">They range in price and speed from low to high as follows:</span></span>

| <span data-ttu-id="313fd-159">**Azure VM シリーズ**</span><span class="sxs-lookup"><span data-stu-id="313fd-159">**Azure VM series**</span></span> | <span data-ttu-id="313fd-160">**NVIDIA GPU**</span><span class="sxs-lookup"><span data-stu-id="313fd-160">**NVIDIA GPU**</span></span> |
|---------------------|----------------|
| <span data-ttu-id="313fd-161">NC</span><span class="sxs-lookup"><span data-stu-id="313fd-161">NC</span></span>                  | <span data-ttu-id="313fd-162">K80</span><span class="sxs-lookup"><span data-stu-id="313fd-162">K80</span></span>            |
| <span data-ttu-id="313fd-163">ND</span><span class="sxs-lookup"><span data-stu-id="313fd-163">ND</span></span>                  | <span data-ttu-id="313fd-164">P40</span><span class="sxs-lookup"><span data-stu-id="313fd-164">P40</span></span>            |
| <span data-ttu-id="313fd-165">NCv2</span><span class="sxs-lookup"><span data-stu-id="313fd-165">NCv2</span></span>                | <span data-ttu-id="313fd-166">P100</span><span class="sxs-lookup"><span data-stu-id="313fd-166">P100</span></span>           |
| <span data-ttu-id="313fd-167">NCv3</span><span class="sxs-lookup"><span data-stu-id="313fd-167">NCv3</span></span>                | <span data-ttu-id="313fd-168">V100</span><span class="sxs-lookup"><span data-stu-id="313fd-168">V100</span></span>           |

<span data-ttu-id="313fd-169">Microsoft では、お使いのトレーニングをスケールアウトするよりも、まずはスケールアップすることを推奨しました。たとえば、K80 のクラスターを試す前に、単一の V100 を試してください。</span><span class="sxs-lookup"><span data-stu-id="313fd-169">We recommended scaling up your training before scaling out. For example, try a single V100 before trying a cluster of K80s.</span></span>

<span data-ttu-id="313fd-170">次のグラフは、Batch AI 上で TensorFlow および Horovod を使用して実施された[ベンチマーク テスト][benchmark]に基づいて、異なる GPU の種類におけるパフォーマンスの差異を示しています。</span><span class="sxs-lookup"><span data-stu-id="313fd-170">The following graph shows the performance differences for different GPU types based on [benchmarking tests][benchmark] carried out using TensorFlow and Horovod on Batch AI.</span></span> <span data-ttu-id="313fd-171">グラフでは、異なる GPU の種類と MPI バージョンにおいて、各種のモデルにわたる 32 GPU クラスターのスループットを示しています。</span><span class="sxs-lookup"><span data-stu-id="313fd-171">The graph shows throughput of 32 GPU clusters across various models, on different GPU types and MPI versions.</span></span> <span data-ttu-id="313fd-172">モデルは、TensorFlow 1.9 で実装されました。</span><span class="sxs-lookup"><span data-stu-id="313fd-172">Models were implemented in TensorFlow 1.9</span></span>

![GPU クラスター上での TensorFlow モデルに対するスループットの結果][2]

<span data-ttu-id="313fd-174">前記の表に示した各 VM シリーズには、InfiniBand を利用した構成が組み込まれています。</span><span class="sxs-lookup"><span data-stu-id="313fd-174">Each VM series shown in the previous table includes a configuration with InfiniBand.</span></span> <span data-ttu-id="313fd-175">分散トレーニングを実行する場合、ノード間でのより高速な通信のために、InfiniBand 構成を使用してください。</span><span class="sxs-lookup"><span data-stu-id="313fd-175">Use the InfiniBand configurations when you run distributed training, for faster communication between nodes.</span></span> <span data-ttu-id="313fd-176">また、InfiniBand は、InfiniBand を活用できるフレームワークにおいて、トレーニングのスケーリング効率を向上させます。</span><span class="sxs-lookup"><span data-stu-id="313fd-176">InfiniBand also increases the scaling efficiency of the training for the frameworks that can take advantage of it.</span></span> <span data-ttu-id="313fd-177">詳細については、Infiniband の[ベンチマークの比較][benchmark]に関する記事をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="313fd-177">For details, see the Infiniband [benchmark comparison][benchmark].</span></span>

<span data-ttu-id="313fd-178">Batch AI では [blobfuse][blobfuse] アダプターを使用して Blob ストレージをマウントできますが、必要なスループットを処理するにはパフォーマンスが不十分なので、分散トレーニングに Blob ストレージをこのように使用することはお勧めしません。</span><span class="sxs-lookup"><span data-stu-id="313fd-178">Although Batch AI can mount Blob storage using the [blobfuse][blobfuse] adapter, we don't recommend using Blob Storage this way for distributed training, because the performance isn't good enough to handle the necessary throughput.</span></span> <span data-ttu-id="313fd-179">代わりに、アーキテクチャの図に示すように、Batch AI ファイル サーバーにデータを移動してください。</span><span class="sxs-lookup"><span data-stu-id="313fd-179">Move the data to a Batch AI file server instead, as shown in the architecture diagram.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="313fd-180">スケーラビリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="313fd-180">Scalability considerations</span></span>

<span data-ttu-id="313fd-181">ネットワークのオーバーヘッドが原因で、分散トレーニングのスケーリング効率は常に 100 パーセント未満になります &mdash; デバイス間でモデル全体を同期すると、ボトルネックになります。</span><span class="sxs-lookup"><span data-stu-id="313fd-181">The scaling efficiency of distributed training is always less than 100 percent due to network overhead &mdash; syncing the entire model between devices becomes a bottleneck.</span></span> <span data-ttu-id="313fd-182">そのため、分散トレーニングは、単一の GPU 上で適切なバッチ サイズを使用してトレーニングできない大規模なモデルや、シンプルな並列手法でモデルを分散することでは対処できない問題に、最も適しています。</span><span class="sxs-lookup"><span data-stu-id="313fd-182">Therefore, distributed training is most suited for large models that cannot be trained using a reasonable batch size on a single GPU, or for problems that cannot be addressed by distributing the model in a simple, parallel way.</span></span>

<span data-ttu-id="313fd-183">分散トレーニングは、ハイパーパラメーター探索の実行には推奨されていません。</span><span class="sxs-lookup"><span data-stu-id="313fd-183">Distributed training is not recommended for running hyperparameter searches.</span></span> <span data-ttu-id="313fd-184">スケーリング効率がパフォーマンスに影響を及ぼし、複数のモデル構成を別個にトレーニングするよりも、分散手法の効率を低下させます。</span><span class="sxs-lookup"><span data-stu-id="313fd-184">The scaling efficiency affects performance and makes a distributed approach less efficient than training multiple model configurations separately.</span></span>

<span data-ttu-id="313fd-185">スケーリング効率を向上させる 1 つの方法は、バッチ サイズを引き上げることです。</span><span class="sxs-lookup"><span data-stu-id="313fd-185">One way to increase scaling efficiency is to increase the batch size.</span></span> <span data-ttu-id="313fd-186">ただし、他のパラメーターを調整せずにバッチ サイズを引き上げると、モデルの最終的なパフォーマンスを低下させる可能性があるため、慎重に行う必要があります。</span><span class="sxs-lookup"><span data-stu-id="313fd-186">That must be done carefully, however, because increasing the batch size without adjusting the other parameters can hurt the model's final performance.</span></span>

## <a name="storage-considerations"></a><span data-ttu-id="313fd-187">ストレージに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="313fd-187">Storage considerations</span></span>

<span data-ttu-id="313fd-188">ディープ ラーニング モデルをトレーニングするときに、見落とされがちな側面は、データが格納される場所です。</span><span class="sxs-lookup"><span data-stu-id="313fd-188">When training deep learning models, an often-overlooked aspect is where the data is stored.</span></span> <span data-ttu-id="313fd-189">ストレージが遅すぎて GPU の需要に対応できない場合、トレーニング パフォーマンスが低下する場合があります。</span><span class="sxs-lookup"><span data-stu-id="313fd-189">If the storage is too slow to keep up with the demands of the GPUs, training performance can degrade.</span></span>

<span data-ttu-id="313fd-190">Batch AI では、多数のストレージ ソリューションをサポートしています。</span><span class="sxs-lookup"><span data-stu-id="313fd-190">Batch AI supports many storage solutions.</span></span> <span data-ttu-id="313fd-191">Batch AI ファイル サーバーは使いやすさとパフォーマンスの最適なバランスを提供しているため、このアーキテクチャでは Batch AI ファイル サーバーを使用しています。</span><span class="sxs-lookup"><span data-stu-id="313fd-191">This architecture uses a Batch AI file server, because it provides the best tradeoff between ease of use and performance.</span></span> <span data-ttu-id="313fd-192">最適なパフォーマンスのためには、データをローカルに読み込みます。</span><span class="sxs-lookup"><span data-stu-id="313fd-192">For best performance, load the data locally.</span></span> <span data-ttu-id="313fd-193">しかし、すべてのノードにおいて Blob ストレージからデータをダウンロードする必要があり、ImageNet データセットの場合、このダウンロードに数時間かかる可能性があるため、これは煩雑になることがあります。</span><span class="sxs-lookup"><span data-stu-id="313fd-193">However, this can be cumbersome, because all the nodes must download the data from Blob Storage, and with the ImageNet dataset, this can take hours.</span></span> <span data-ttu-id="313fd-194">[Azure Premium Blob Storage][blob] (限定パブリック プレビュー) は、検討すべきもう 1 つのオプションです。</span><span class="sxs-lookup"><span data-stu-id="313fd-194">[Azure Premium Blob Storage][blob] (limited public preview) is another good option to consider.</span></span>

<span data-ttu-id="313fd-195">分散トレーニング用のデータ ストアとして Blob および File ストレージをマウントしないでください。</span><span class="sxs-lookup"><span data-stu-id="313fd-195">Do not mount Blob and File storage as data stores for distributed training.</span></span> <span data-ttu-id="313fd-196">非常に低速であり、トレーニング パフォーマンスの妨げになります。</span><span class="sxs-lookup"><span data-stu-id="313fd-196">They are too slow and will hinder training performance.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="313fd-197">セキュリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="313fd-197">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="313fd-198">Azure Blob Storage へのアクセスの制限</span><span class="sxs-lookup"><span data-stu-id="313fd-198">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="313fd-199">このアーキテクチャでは、[ストレージ アカウント キー][security-guide]を使用して Blob ストレージにアクセスします。</span><span class="sxs-lookup"><span data-stu-id="313fd-199">This architecture uses [storage account keys][security-guide] to access the Blob storage.</span></span> <span data-ttu-id="313fd-200">さらに制御と保護を強化するには、共有アクセス署名 (SAS) を代わりに使用することを検討します。</span><span class="sxs-lookup"><span data-stu-id="313fd-200">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="313fd-201">これは、ストレージ内のオブジェクトへの制限付きアクセスを付与し、アカウント キーをハード コーディングしたり、それをプレーンテキストで保存したりする必要はありません。</span><span class="sxs-lookup"><span data-stu-id="313fd-201">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="313fd-202">また、SAS を使用すると、ストレージ アカウントに適切なガバナンスがあること、およびアクセスがそれを必要とするユーザーだけに付与されることを保証することができます。</span><span class="sxs-lookup"><span data-stu-id="313fd-202">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="313fd-203">ストレージ キーはワークロードのすべての入出力データに対するフル アクセス権を与えるため、データの機密性がさらに高いシナリオでは、すべてのストレージ キーが保護されるようにします。</span><span class="sxs-lookup"><span data-stu-id="313fd-203">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="313fd-204">保存時および稼働時のデータの暗号化</span><span class="sxs-lookup"><span data-stu-id="313fd-204">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="313fd-205">機密データを使用するシナリオでは、保存データ &mdash; つまりストレージ内にあるデータを暗号化します。</span><span class="sxs-lookup"><span data-stu-id="313fd-205">In scenarios that use sensitive data, encrypt the data at rest &mdash; that is, the data in storage.</span></span> <span data-ttu-id="313fd-206">データがある場所から次の場所に移動されるたびに、SSL を使用してデータ転送をセキュリティ保護します。</span><span class="sxs-lookup"><span data-stu-id="313fd-206">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="313fd-207">詳細については、「[Azure Storage セキュリティ ガイド][security-guide]」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="313fd-207">For more information, see the [Azure Storage security guide][security-guide].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="313fd-208">仮想ネットワーク内のデータのセキュリティ保護</span><span class="sxs-lookup"><span data-stu-id="313fd-208">Secure data in a virtual network</span></span>

<span data-ttu-id="313fd-209">運用環境にデプロイする場合、指定した仮想ネットワークのサブネットに Batch AI クラスターをデプロイすることを検討します。</span><span class="sxs-lookup"><span data-stu-id="313fd-209">For production deployments, consider deploying the Batch AI cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="313fd-210">これにより、クラスター内のコンピューティング ノードは、他の仮想マシンやオンプレミスのネットワークと安全に通信できます。</span><span class="sxs-lookup"><span data-stu-id="313fd-210">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="313fd-211">また、Blob ストレージを利用した[サービス エンドポイント][endpoints]を使って、仮想ネットワークからのアクセスを許可したり、Batch AI を備えた仮想ネットワークの内部で単一ノード NFS を使用したりすることも可能です。</span><span class="sxs-lookup"><span data-stu-id="313fd-211">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Batch AI.</span></span>

## <a name="monitoring-considerations"></a><span data-ttu-id="313fd-212">監視に関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="313fd-212">Monitoring considerations</span></span>

<span data-ttu-id="313fd-213">ジョブの実行中は、進行状況を監視し、想定どおりに動作していることを確認することが重要です。</span><span class="sxs-lookup"><span data-stu-id="313fd-213">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="313fd-214">ただし、アクティブなノードのクラスター全体を監視するのは困難な場合があります。</span><span class="sxs-lookup"><span data-stu-id="313fd-214">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="313fd-215">Batch AI ファイル サーバーは、Azure portal 経由または [Azure CLI][cli] および Python SDK 経由で管理できます。</span><span class="sxs-lookup"><span data-stu-id="313fd-215">The Batch AI file servers can be managed through the Azure portal or though the [Azure CLI][cli] and Python SDK.</span></span> <span data-ttu-id="313fd-216">クラスターの全体的な状態を把握するには、Azure portal 内で **[Batch AI]** に移動して、クラスター ノードの状態を調べます。</span><span class="sxs-lookup"><span data-stu-id="313fd-216">To get a sense of the overall state of the cluster, navigate to **Batch AI** in the Azure portal to inspect the state of the cluster nodes.</span></span> <span data-ttu-id="313fd-217">ノードが非アクティブになった場合、またはジョブが失敗した場合は、エラー ログが Blob ストレージに保存され、Azure portal の **[ジョブ]** の下からもアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="313fd-217">If a node is inactive or a job fails, the error logs are saved to blob storage, and are also accessible in the Azure Portal under **Jobs**.</span></span>

<span data-ttu-id="313fd-218">ログを [Azure Application Insights][ai] に接続するか、または Batch AI クラスターとそのジョブの状態をポーリングする別個のプロセスを実行することで、監視を強化します。</span><span class="sxs-lookup"><span data-stu-id="313fd-218">Enrich monitoring by connecting logs to [Azure Application Insights][ai] or by running separate processes that poll for the state of the Batch AI cluster and its jobs.</span></span>

<span data-ttu-id="313fd-219">Batch AI では、関連付けられている BLOB ストレージ アカウントに、すべての stdout/stderr を自動的に記録します。</span><span class="sxs-lookup"><span data-stu-id="313fd-219">Batch AI automatically logs all stdout/stderr to the associate Blob storage account.</span></span> <span data-ttu-id="313fd-220">[Azure Storage Explorer][storage-explorer] などのストレージ ナビゲーション ツールを使用すると、ログ ファイルをナビゲートするときのエクスペリエンスが簡単になります。</span><span class="sxs-lookup"><span data-stu-id="313fd-220">Use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] for an easier experience when navigating log files.</span></span>

<span data-ttu-id="313fd-221">また、各ジョブのログをストリーミングすることも可能です。</span><span class="sxs-lookup"><span data-stu-id="313fd-221">It is also possible to stream the logs for each job.</span></span> <span data-ttu-id="313fd-222">このオプションの詳細については、[GitHub][github] 上の開発手順をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="313fd-222">For details about this option, see the development steps on [GitHub][github].</span></span>

## <a name="deployment"></a><span data-ttu-id="313fd-223">Deployment</span><span class="sxs-lookup"><span data-stu-id="313fd-223">Deployment</span></span>

<span data-ttu-id="313fd-224">このアーキテクチャのリファレンス実装は、[GitHub][github] で入手できます。</span><span class="sxs-lookup"><span data-stu-id="313fd-224">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="313fd-225">そこに示された手順に従って、GPU 対応 VM のクラスター間でディープ ラーニング モデルの分散トレーニングを実施してください。</span><span class="sxs-lookup"><span data-stu-id="313fd-225">Follow the steps described there to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="313fd-226">次の手順</span><span class="sxs-lookup"><span data-stu-id="313fd-226">Next steps</span></span>

<span data-ttu-id="313fd-227">このアーキテクチャからの出力は、Blob ストレージに保存されるトレーニング済みモデルです。</span><span class="sxs-lookup"><span data-stu-id="313fd-227">The output from this architecture is a trained model that is saved to blob storage.</span></span> <span data-ttu-id="313fd-228">リアルタイム スコアリングまたはバッチ スコアリングのどちらかに、このモデルを運用化できます。</span><span class="sxs-lookup"><span data-stu-id="313fd-228">You can operationalize this model for either real-time scoring or batch scoring.</span></span> <span data-ttu-id="313fd-229">詳細については、次の参照アーキテクチャをご覧ください。</span><span class="sxs-lookup"><span data-stu-id="313fd-229">For more information, see the following reference architectures:</span></span>

- <span data-ttu-id="313fd-230">[Azure での Python scikit-learn モデルおよびディープ ラーニング モデルのリアルタイム スコアリング][real-time-scoring]</span><span class="sxs-lookup"><span data-stu-id="313fd-230">[Real-time scoring of Python Scikit-Learn and deep learning models on Azure][real-time-scoring]</span></span>
- <span data-ttu-id="313fd-231">[ディープ ラーニング モデル用の Azure でのバッチ スコアリング][batch-scoring]</span><span class="sxs-lookup"><span data-stu-id="313fd-231">[Batch scoring on Azure for deep learning models][batch-scoring]</span></span>

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning