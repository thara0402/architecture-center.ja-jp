---
title: 自動スケール ガイダンス
description: 自動スケールによってアプリケーションに必要なリソースを動的に割り当てる方法に関するガイダンス。
author: dragon119
ms.date: 05/17/2017
pnp.series.title: Best Practices
ms.openlocfilehash: 1afbb7d48329d84979aa72b7e0707442cacfa45e
ms.sourcegitcommit: 94d50043db63416c4d00cebe927a0c88f78c3219
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 09/28/2018
ms.locfileid: "47429419"
---
# <a name="autoscaling"></a>自動スケール
[!INCLUDE [header](../_includes/header.md)]

自動スケールは、パフォーマンス要件に合わせてリソースを動的に割り当てるプロセスです。 作業量が増加すると、アプリケーションで、サービス レベル アグリーメント (SLA) に準拠し、必要なパフォーマンス レベルを維持するために追加のリソースが必要になる場合があります。 需要が減り、追加のリソースが必要なくなった場合は、コストを下げるために割り当てを解除できます。

自動スケールは、クラウドでホストされている環境の弾力性を活用しながら、管理オーバーヘッドを削減します。 これにより、オペレーターがシステムのパフォーマンスを常時監視したり、リソースの追加や削除を判断する必要がなくなります。

アプリケーションを拡張する方法は、主に 2 つあります。 

* **垂直方向のスケーリング**スケール アップまたはスケール ダウンとも呼ばれ、リソースの容量を変更することを指します。 たとえば、アプリケーションをより大きい VM に移動する場合です。 垂直方向のスケーリングでは、一般的に再デプロイのためにシステムの使用を一時的に中断する必要があります。 したがって、垂直方向スケーリングの自動化はあまり一般的ではありません。
* **水平方向のスケーリング**、スケール アウトまたはスケール インとも呼ばれ、リソースからインスタンスを追加または削除することを指します。 新しいリソースのプロビジョニング中も、アプリケーションの実行は中断されることなく継続されます。 プロビジョニング プロセスが完了すると、ソリューションはこれらの追加リソース上に展開されます。 需要が減った場合は、追加のリソースを正常にシャット ダウンし、割り当てを取り消せます。 

Microsoft Azure を含む、多くのクラウドベース システムでは、水平自動スケールがサポートされています。 この記事の残りの部分では、水平自動スケールについて説明します。

> [!NOTE]
> 自動スケールは、ほとんどの場合、コンピューティング リソースに適用されます。 データベースまたはメッセージ キューは水平方向に拡張できますが、これには、一般的に自動化されていない[データのパーティション分割][data-partitioning]が必要になります。
>

## <a name="overview"></a>概要

通常、自動スケール戦略を実装するには、次のコンポーネントやプロセスが必要になります。

* アプリケーション、サービス、およびインフラストラクチャのレベルで運用する、インストルメンテーションおよび監視システム。 これらのシステムは、応答時間、キューの長さ、CPU 使用率、メモリ使用量などの主要メトリックをキャプチャします。
* 定義済みのしきい値またはスケジュールを基準にこれらのメトリックを評価し、拡張するかどうかを決定する意思決定ロジック。
* システムを拡張するコンポーネントです。
* 自動スケール戦略を期待どおりに機能させるための、戦略のテスト、監視、および調整。

Azure には、一般的なシナリオに対応するための自動スケール メカニズムが組み込まれています。 特定のサービスやテクノロジに自動スケール機能が組み込まれていない場合、またはその機能以上の特定の自動スケールの要件がある場合は、カスタム実装を検討できます。 カスタム実装では、運用およびシステム メトリックを収集し、メトリックを解析して、それに従ってリソースを拡張します。

## <a name="configure-autoscaling-for-an-azure-solution"></a>Azure ソリューションの自動スケールの構成

Azure には、ほぼすべてのコンピューティング オプションに対応する自動スケール機能が組み込まれています。

* **Virtual Machines** は、Azure の仮想マシン セットをグループとして管理する方法である、[VM Scale Sets][vm-scale-sets] を使用して自動スケールをサポートします。 「[自動スケールと仮想マシン スケール セットの使用方法][vm-scale-sets-autoscale]」を参照してください。

* **Service Fabric** でも自動スケールは VM Scale Sets を通してサポートされています。 Service Fabric クラスターにあるすべてのノード タイプは、個別の VM Scale Sets として設定されています。 これにより、各ノード タイプはそれぞれ個別にスケール インまたはスケール アウトできます。 「[自動スケール ルールを使用した Service Fabric クラスターのスケールインとスケールアウト][service-fabric-autoscale]」を参照してください。

* **Azure App Service** には、自動スケール機能が組み込まれています。 自動スケール設定は、App Service 内のすべてのアプリに適用されます。 「[手動または自動によるインスタンス数のスケール変更][app-service-autoscale]」を参照してください。

* **Azure Cloud Services** には、ロール レベルの自動スケールが組み込まれています。 「[ポータルでクラウド サービスの自動スケールを構成する方法][cloud-services-autoscale]」を参照してください。

これらの計算オプションはすべて [Azure Monitor 自動スケール][monitoring]を使用して、一般的な自動スケール機能を提供します。

* **Azure Functions** は、自動スケール規則を構成する必要がない点で、以前のコンピューティング オプションとは異なります。 Azure Functions では、コードの実行中に、負荷を処理するために必要なコンピューティング能力が自動的に割り当てられます。 詳細については、「[Azure Functions の適切なホスティング プランを選択する][functions-scale]」を参照してください。

最後に、カスタムの自動スケール ソリューションが役に立つ場合があります。 たとえば、Azure 診断およびアプリケーションベースのメトリックやカスタム コードを使用して、アプリケーション メトリックを監視およびエクスポートできます。 その後、これらのメトリックに基づいてカスタムの規則を定義し、Resource Manager REST API を使用して、自動スケールを開始できます。 ただし、カスタム ソリューションの実装は容易ではないため、前述の手法では要件を完全に満たすことができない場合にのみ検討してください。

プラットフォームに組み込まれた自動スケール機能で要件を満たせる場合は、それを使用します。 満たせない場合は、より複雑なスケーリング機能が本当に必要かどうかを慎重に検討してください。 追加要件には、より詳細な制御、スケーリングのトリガー イベントに対するさまざまな方法での検出、サブスクリプション間でのスケーリング、他の種類のリソースのスケーリングなどが挙げられます。

## <a name="use-azure-monitor-autoscale"></a>Azure Monitor 自動スケールの使用

[Azure Monitor 自動スケール][monitoring]は、VM Scale Sets、Azure App Service および Azure Cloud Service に共通の自動スケール機能です。 スケーリングは、スケジュールに従って、または CPU またはメモリ使用率などのランタイム メトリックに基づいて実行できます。 次に例を示します。

- 平日は 10 個のインスタンスにスケール アウトとし、土曜日と日曜日は 4 つのインスタンスにスケール インします。 
- 平均 CPU 使用率が 70% を上回る場合はインスタンス 1 つ分スケール アウトし、CPU 使用率が 50% を下回る場合はインスタンス 1 つ分スケール インします。
- キュー内のメッセージの数が特定のしきい値を超える場合は、インスタンス 1 つ分スケール アウトします。

組み込まれているメトリックの一覧については、「[Azure Monitor の自動スケールの一般的なメトリック][autoscale-metrics]」を参照してください。 Application Insights を使用してカスタム メトリックを実装することもできます。 

自動スケールは、PowerShell、Azure CLI、Azure Resource Manager テンプレートの場合、または Azure ポータルを使用して構成できます。 より詳細な制御は、[Azure Resource Manager REST API](https://msdn.microsoft.com//library/azure/dn790568.aspx) を使用して構成できます。 [Azure Monitoring Service 管理ライブラリ](https://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Monitoring)と [Microsoft Insights ライブラリ](https://www.nuget.org/packages/Microsoft.Azure.Insights/) (プレビュー) は SDK です。REST API を利用して、さまざまなリソースからメトリックを収集し、自動スケールを実行することができます。 Azure Resource Manager にリソースが対応していない場合や、Azure Cloud Services を使用している場合は、Service Management REST API を自動スケールに使用できます。 それ以外のすべてのケースでは、Azure Resource Manager を使用してください。

Azure 自動スケールを使用する場合は、次の点を考慮してください。

* スケジュールされた自動スケールを使用し、予測される需要ピーク時に対応するためにインスタンスを追加および削除することにより、十分な精度でアプリケーションの負荷を予測できるかどうかを検討します。 これが不可能な場合は、実行時に収集されたメトリックに基づくリアクティブ自動スケールを使用して、予測不可能な需要の変化にアプリケーションが対応できるようにします。 通常は、これらの手法を組み合わせることができます。 たとえば、アプリケーションが最もビジー状態になることがわかっている時間のスケジュールに基づいてリソースを追加する戦略を作成します。 これにより、新しいインスタンスの開始時に遅延することなく、必要なときに容量を確保できます。 また、スケジュールされたルールごとに、その期間のリアクティブ自動スケールを有効にし、持続的だが予測不可能な需要ピークをアプリケーションが処理できるメトリックを定義します。
* 特にアプリケーションが初めてデプロイされたときは、メトリックと容量要件の関係を理解しにくいことがよくあります。 最初は容量を少し余分に追加し、その後自動スケール ルールを監視および調整して、実際の負荷に容量を近づけることをお勧めします。
* 自動スケール ルールを構成し、一定期間、アプリケーションのパフォーマンスを監視します。 この監視結果を使用して、必要に応じてシステムをスケールする方法を調整します。 ただし、自動スケールは即時に結果を得られるプロセスではありません。 指定したしきい値を超過する (または下回る) 平均 CPU 使用率など、何らかのメトリックに反応するには一定の時間を要します。
* 測定されたトリガー属性 (CPU 使用率やキューの長さなど) に基づく検出メカニズムを使用する自動スケール ルールでは、瞬間的な値ではなく、長期にわたって集計された値を使用して自動スケール アクションがトリガーされます。 既定では、集計は値の平均になります。 これにより、システムの反応が早すぎたり、急激な変動が生じたりすることが回避されます。 また、自動的に開始された新しいインスタンスが実行モードになるまでの時間を確保し、新しいインスタンスの開始中に追加の自動スケール アクションが実行されないようにすることもできます。 Azure Cloud Services や Azure Virtual Machines については、既定の集計期間は 45 分であるため、需要の急増に反応して自動スケールをトリガーするメトリックに、この長さまでの時間を設定できます。 SDK を使って集計期間を変更できますが、25 分未満の期間を設定すると、予期しない結果が生じる場合があります。 Web Apps では、平均の期間はかなり短く、平均のトリガー測定への変更後、約 5 分間で新しいインスタンスを使用できるようになります。
* ポータルではなく SDK を使用して自動スケールを構成する場合は、ルールが有効な期間の、より詳細なスケジュールを指定できます。 独自のメトリックを作成し、自動スケール ルールで既存のメトリックと共に使用したり、単独で使用したりすることもできます。 たとえば、1 秒あたりの要求数や使用可能なメモリ平均量などの代替カウンターを使用することも、特定のビジネス プロセスを測定するカスタム カウンターを使用することもできます。
* Service Fabric を自動スケールする場合、クラスター内のノードの種類は、バックエンドでは VM Scale Sets で構成されるため、ノードの種類ごとに自動スケール ルールを設定する必要があります。 自動スケールを設定する前に、必要なノードの数を考慮します。 ノードの種類がプライマリである場合に必要なノードの最小数は、選択した信頼性のレベルによって決まります。 詳細については、「[自動スケール ルールを使用した Service Fabric クラスターのスケールインとスケールアウト](https://docs.microsoft.com/azure/service-fabric/service-fabric-cluster-scale-up-down)」を参照してください。
* ポータルを使用して、SQL Database のインスタンスやキューなどのリンク リソースを Cloud Service インスタンスにリンクできます。 これにより、リンクされたリソースごとに、より簡単に別個の手動および自動スケーリング構成オプションにアクセスできます。 詳細については、「[方法: クラウド サービスに対するリソースのリンク](/azure/cloud-services/cloud-services-how-to-manage)」を参照してください。
* 複数のポリシーとルールを構成するときは、それらが互いに競合する可能性があります。 自動スケールでは次の競合の解決ルールに従って、常に十分な数のインスタンスが実行されます。
  * スケールアウト操作は、スケールイン操作よりも常に優先されます。
  * スケールアウト操作が競合した場合は、インスタンス数を最も増加させるルールが優先されます。
  * スケールイン操作が競合した場合は、インスタンス数を最も減少させるルールが優先されます。
* App Service Environment では、任意のワーカー プールまたはフロントエンド メトリックを使用して、自動スケール ルールを定義することができます。 詳細については、「[Autoscaling and App Service Environment (自動スケールと App Service Environment v1)](/azure/app-service/app-service-environment-auto-scale)」を参照してください。

## <a name="application-design-considerations"></a>アプリケーション設計に関する考慮事項
自動スケールは単純なソリューションではありません。 単にリソースをシステムに追加したり、実行するプロセスのインスタンスを増やしたりするだけで、システムのパフォーマンスが確実に向上するわけではありません。 自動スケール戦略を作成するときには、次の点を考慮してください。

* システムは、水平方向にスケールできるように設計されている必要があります。 インスタンスのアフィニティに関して仮説を立てることは避けます。あるコードが常にプロセスの特定のインスタンスで実行されている必要があるようなソリューションを作成しないでください。 クラウド サービスまたは Web サイトを水平方向にスケールする場合、同じソースからの一連の要求が常に同じインスタンスにルーティングされると想定しないでください。 同様の理由で、アプリケーションからの一連の要求が常にサービスの同じインスタンスにルーティングされなくても済むように、サービスはステートレスになるように設計します。 キューからメッセージを読み取り、それらを処理するサービスを設計する場合、サービスのどのインスタンスが特定のメッセージを処理するかを事前に想定しないでください。 キューの長さが長くなると、自動スケールによってサービスの追加インスタンスが開始される可能性があるためです。 「[競合コンシューマー パターン][competing-consumers]」には、この状況に対処する方法が記載されています。
* ソリューションで長期タスクを実装する場合、このタスクを作成して、スケールアウトとスケールインの両方がサポートされるようにします。 しかるべき注意を払わなければ、そのようなタスクにより、システムをスケールインするときにプロセスのインスタンスが正常にシャットダウンされなかったり、プロセスが強制的に終了された場合にデータが失われたりする可能性があります。 可能であれば、長期タスクをリファクタリングし、プロセスを分割して、より小さい、個別のまとまりで実行されるようにします。 「[Pipes and Filters pattern (パイプとフィルター パターン)][pipes-and-filters] 」には、これを行う方法の例が記載されています。
* あるいは、一定の間隔でタスクの状態に関する情報を記録するチェックポイント メカニズムを使用し、タスクを実行しているプロセスのすべてのインスタンスがアクセスできる永続的ストレージにその状態を保存することもできます。 このようにすることで、プロセスがシャットダウンされても、別のインスタンスを使用して、そのプロセスによって実行されていた作業を最後のチェックポイントから再開できます。
* クラウド サービスでホストされているアプリケーションの worker ロールなど、別個のコンピューティング インスタンスでバックグラウンド タスクが実行されている場合、別のスケーリング ポリシーを使用してアプリケーションのさまざまな部分をスケールする必要が生じることがあります。 たとえば、バックグラウンド コンピューティング インスタンスの数を増やさずに、ユーザーインターフェイス (UI) コンピューティング インスタンスをさらにデプロイしたり、その反対の処理を行ったりしなくてはならない場合があります。 異なるレベルのサービス (Basic、および Premium サービス パッケージなど) を提供する場合、SLA に準拠するために、Basic サービス パッケージのコンピューティング リソースよりも、Premium サービス パッケージのコンピューティング リソースの方をより積極的にスケールアウトする必要が生じる可能性があります。
* 自動スケール戦略の基準として、UI とバックグラウンド コンピューティング インスタンスが通信に使用するキューの長さを使用することを検討してください。 これは、バックグラウンド タスクの現在の負荷と処理能力の間の不均衡または差異を最も明確に示す指標です。
* 1 時間当たりに行われた命令数や複雑なトランザクションの平均実行時間など、ビジネス プロセスを測定するカウンターに基づいて自動スケール戦略を作成する場合は、そのようなタイプのカウンターから得られる結果と実際のコンピューティング能力の要件の関係を完全に理解してください。 ビジネス プロセス カウンターの変更に応じて、複数のコンポーネントまたはコンピューティング ユニットをスケールする必要が生じる場合があります。  
* システムによって過度なスケールアウトが試行されたり、多数のインスタンス実行に関連するコストが生じたりしないようにするために、自動的に追加できるインスタンスの最大数を制限することを検討してください。 大部分の自動スケール メカニズムでは、任意のルールに基づいてインスタンスの最小数と最大数を指定できます。 また、インスタンスの最大数を設定しても、システムが依然としてオーバーロードの状態である場合には、システムによって提供される機能を適度に低下させることを検討してください。
* 自動スケールは、ワークロードの急激な増加を処理する最も適切なメカニズムではない場合もあることに留意してください。 サービスの新しいインスタンスをプロビジョニングして開始したり、リソースをシステムに追加したりする作業は時間を要します。また、追加したそれらのリソースが使用できるようになるまでに、ピーク需要が過ぎてしまう可能性もあります。 このようなときは、サービスを調整したほうがよい場合があります。 詳細については、「[調整パターン][throttling]」を参照してください。
* 逆に、ボリュームが急激に変動する場合にすべての要求を処理する容量が必要であり、コストが主な検討要因ではない場合は、追加インスタンスをより迅速に開始する積極的な自動スケール戦略の使用を検討してください。 また、負荷が予見される前に、十分な数のインスタンスを開始して最大負荷に対応するようにスケジュール設定されたポリシーを使用する方法もあります。
* 自動スケール メカニズムでは、自動スケール プロセスを監視し、各自動スケール イベントの詳細 (イベントがトリガーされた理由、追加または削除されたリソース、それらの日時) を記録する必要があります。 カスタムの自動スケール メカニズムを作成する場合は、この機能が組み込まれていることを確認してください。 情報を分析して、自動スケール戦略の効果を測定し、必要に応じて調整します。 使用パターンがより明確な場合は短期間の調整を行い、ビジネスが拡大したり、アプリケーションの要件が増加したりする場合は長期間の調整を行うことができます。 アプリケーションが自動スケールの定義された上限に到達すると、このメカニズムにより、必要に応じて追加リソースを手動で開始できる操作者にアラートが出される可能性もあります。 このような状況では、ワークロードが軽減された後、操作者はそれらのリソースを手動で削除しなくてはならなくなる場合もあることに留意してください。

## <a name="related-patterns-and-guidance"></a>関連のあるパターンとガイダンス
自動スケールを実装する場合、次のパターンとガイダンスも関連する可能性があります。

* [調整パターン][throttling]。 このパターンは、需要の増加によってリソースに極端な負荷がかけられた場合に、アプリケーションがどのようにして継続的に機能し、SLA に準拠できるかを示します。 自動スケールとともに調整を使用して、システムがスケールアウトしている間にシステムに過剰な負荷が掛からないようにすることができます。
* [競合コンシューマー パターン][competing-consumers]。 このパターンは、任意のアプリケーション インスタンスからのメッセージを処理できるサービス インスタンスのプールを実装する方法を示します。 自動スケールを使用して、予測されるワークロードに対処できるように、サービス インスタンスを開始および停止できます。 この手法を使用することで、システムは複数のメッセージを同時に処理し、スループットを最適化し、拡張性と可用性を向上させ、ワークロードのバランスを取ることができます。
* [監視と診断](./monitoring.md)。 インストルメンテーションと製品利用統計情報は、自動スケール プロセスを促進できる情報を収集するために不可欠です。


<!-- links -->

[monitoring]: /azure/monitoring-and-diagnostics/monitoring-overview-autoscale
[app-service-autoscale]: /azure/monitoring-and-diagnostics/insights-how-to-scale?toc=%2fazure%2fapp-service-web%2ftoc.json#scaling-based-on-a-pre-set-metric
[app-service-plan]: /azure/app-service/azure-web-sites-web-hosting-plans-in-depth-overview
[autoscale-metrics]: /azure/monitoring-and-diagnostics/insights-autoscale-common-metrics
[cloud-services-autoscale]: /azure/cloud-services/cloud-services-how-to-scale-portal
[competing-consumers]: ../patterns/competing-consumers.md
[data-partitioning]: ./data-partitioning.md
[functions-scale]: /azure/azure-functions/functions-scale
[link-resource-to-cloud-service]: /azure/cloud-services/cloud-services-how-to-manage#how-to-link-a-resource-to-a-cloud-service
[pipes-and-filters]: ../patterns/pipes-and-filters.md
[service-fabric-autoscale]: /azure/service-fabric/service-fabric-cluster-scale-up-down
[throttling]: ../patterns/throttling.md
[vm-scale-sets]: /azure/virtual-machine-scale-sets/virtual-machine-scale-sets-overview
[vm-scale-sets-autoscale]: /azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview
