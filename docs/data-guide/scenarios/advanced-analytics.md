---
title: 高度な分析
description: ''
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: 31ba357fe37b1de35a6eea324d2d1d6766e172e5
ms.sourcegitcommit: 51f49026ec46af0860de55f6c082490e46792794
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/03/2018
ms.locfileid: "30298690"
---
# <a name="advanced-analytics"></a>高度な分析

高度な分析は、従来のビジネス インテリジェンス (BI) の履歴のレポートとデータ集計を超えるもので、数学的、確率論的、統計的なモデリング手法を使用して、予測処理と自動化された意思決定を可能にします。

一般に、高度な分析ソリューションには次のワークロードがあります。

* 対話型のデータの探索と視覚化
* 機械学習モデル トレーニング
* リアルタイムまたはバッチ予測処理

大部分の高度な分析アーキテクチャには、次のコンポーネントの一部またはすべてが含まれています。

* **データ ストレージ**。 高度な分析ソリューションでは、機械学習モデルをトレーニングするためのデータが必要です。 一般にデータ サイエンティストは、その予測される特徴と、それらと予測値 (ラベルと呼ばれます) の間の統計的関係を識別するためにデータを探索する必要があります。 予測ラベルは、将来における何かの財務値や、分単位でのフライト遅延時間のような量的な値にすることができます。 または、"true" または "false"、"フライト遅延" または "フライト遅延なし" のようなカテゴリ クラスか、"低リスク"、"中程度のリスク"、"高リスク" のようなカテゴリを表すことができます。

* **バッチ処理**。 機械学習モデルをトレーニングするには、一般に大量のトレーニング データを処理する必要があります。 モデルのトレーニングには時間がかかることがあります (数分から数時間単位)。 このトレーニングは、Python や R などの言語で記述されたスクリプトを使用して実行でき、HDInsight または Docker コンテナーにホストされている Apache Spark のような分散処理プラットフォームを使用してトレーニング時間を短縮するようにスケールアウトできます。

* **リアルタイム メッセージ取り込み**。 実稼働環境では、多くの高度な分析は、Web サービスとして公開されている予測モデルにリアルタイムのデータ ストリームをフィードします。 一般に、受信データ ストリームはなんらかの形式のキューにキャプチャされ、ストリーム処理エンジンはこのキューからデータをプルし、入力データに対してほぼリアルタイムで予測を適用します。  

* **ストリーム処理**。 トレーニング済みモデルを準備すると、予測 (またはスコア付け) は、一般に特定の特徴セットに対してとても高速に動作します (ミリ秒単位)。 リアルタイム メッセージをキャプチャした後、関連する特徴値を予測サービスに渡して予測ラベルを生成できます。

* **分析データ ストア**。 場合によっては、予測ラベルの値がレポートおよび将来の分析のために分析データ ストアに書き込まれます。

* **分析とレポート**。 名前からわかるように、高度な分析ソリューションは通常、予測データ値を含むなんらかの種類のレポートまたは分析フィードを生成します。 多くの場合、予測ラベル値はリアルタイム ダッシュボードの設定に使用されます。

* **オーケストレーション**。 初期のデータ探索およびモデリングは、データ サイエンティストによって対話的に実行されますが、多くの高度な分析ソリューションは新しいデータでモデルを定期的に再トレーニングして、モデルの精度を継続的に調整します。 この再トレーニングは、オーケストレートされたワークフローを使用して自動化できます。

## <a name="machine-learning"></a>機械学習
機械学習は、予測モデルのトレーニングに使用される数学的なモデリング手法です。 一般原則は、履歴データの大規模なデータセットに統計的アルゴリズムを適用して、そこに含まれているフィールド間の関係を明らかにすることです。

機械学習モデリングは通常、モデルをトレーニングする前にデータを徹底的に探索し、準備する必要があるデータ サイエンティストによって実行されます。 一般に、この探索と準備には多くの対話型データ分析と視覚化が含まれます。通常は、このタスク用に設計された対話型のツールと環境で Python や R などの言語を使用して行います。

場合によっては、Microsoft によって取得および開発されたトレーニング データに付属する[事前トレーニング済みモデル](/machine-learning-server/install/microsoftml-install-pretrained-models)を使用できます。 事前トレーニング済みモデルの利点は、必要なトレーニング データや、大規模なデータセットの管理または複雑なモデルのトレーニングのためのリソースがない場合でも、新しいコンテンツをすぐにスコア付けし、分類できることです。

機械学習には 2 つの大きなカテゴリがあります。

* **教師あり学習**。 教師あり学習は、機械学習で採用されている最も一般的なアプローチです。 教師あり学習モデルでは、ソース データは、1 つまたは複数の "*ラベル*" データ フィールドとの間に数学的なリレーションシップを持つ一連の "*特徴*" データ フィールドから構成されます。 機械学習プロセスのトレーニング フェーズでは、データ セットには特徴と既知のラベルの両方が含まれ、対応するラベル予測を計算するために特徴に対して動作する関数に合わせてアルゴリズムが適用されます。 通常、トレーニング データセットのサブセットが保持され、トレーニング済みモデルのパフォーマンスを検証するために使用されます。 モデルがトレーニングされると、実稼動環境にデプロイでき、不明な値を予測するために使用することができます。 

* **教師なし学習**。 教師なし学習モデルでは、トレーニング データに既知のラベル値は含まれません。 代わりに、アルゴリズムは初めて使用するデータに基づいて予測を行います。 教師なし学習の最も一般的な形式は "*クラスタリング*" です。クラスタリングでは、特徴の統計的類似点に基づいて指定された数のクラスターにデータを分割するための最善の方法がアルゴリズムによって決定されます。 クラスタリングでは、予測結果は入力された特徴が属しているクラスター番号です。 教師なし学習アプローチは、クラスタリングを使用して顧客のデータベース内のユーザー グループを識別するなど、有用な予測を直接生成するために使用できることもありますが、多くの場合、モデルのトレーニングで教師あり学習アルゴリズムに提供する最も有用なデータを識別するために使用されます。

関連 Azure サービス:

- [Azure Machine Learning](/azure/machine-learning/)
- [HDInsight 上の Microsoft Machine Learning Server (Microsoft R Server)](/azure/hdinsight/r-server/r-server-overview)

## <a name="deep-learning"></a>ディープ ラーニング

線形またはロジスティック回帰のような数学的手法に基づく機械学習モデルがしばらくの間使用可能でした。 最近では、ニューラル ネットワークに基づく "*ディープ ラーニング*" 手法の使用が増加しています。 これは、複雑なモデルのトレーニングにかかる時間を短縮するスケーラブルな処理システムの可用性にある程度左右されます。 また、ビッグ データの普及が進み、さまざまなドメインで、ディープ ラーニング モデルを簡単にトレーニングできるようになりました。

高度な分析のクラウド アーキテクチャを設計するときには、ディープ ラーニング モデルの大規模な処理の必要性を検討する必要があります。 これらは、Apache Spark のような分散処理プラットフォームと、GPU ハードウェアへのアクセスが含まれる最新世代の仮想マシンを通じて提供できます。

関連 Azure サービス:

- [ディープ ラーニング仮想マシン](/azure/machine-learning/data-science-virtual-machine/deep-learning-dsvm-overview)
- [HDInsight 上の Apache Spark](/azure/hdinsight/spark/apache-spark-overview)

## <a name="artificial-intelligence"></a>人工知能

人工知能 (AI) は、学習や問題解決など、人間の心に関連付けられている認識機能をコンピューターが模倣するシナリオを表します。 AI は、機械学習アルゴリズムを活用するため、総称と見なされます。 ほとんどの AI ソリューションは、Web サービスとして実装されることの多い予測サービスと、モバイル デバイスやその他のクライアントで実行されている AI アプリによって提示される自然言語インターフェイス (テキストまたは音声を介して対話するチャット ボットなど) の組み合わせに依存します。 場合によっては、機械学習モデルは AI アプリに埋め込まれます。 

## <a name="model-deployment"></a>モデル デプロイ

AI アプリケーションをサポートする予測サービスでは、カスタム機械学習モデル、または事前トレーニング済みモデルへのアクセスを提供する市販の認識サービスを活用できます。 カスタム モデルを運用環境にデプロイするプロセスは運用化と呼ばれ、処理環境内でトレーニングおよびテストされるのと同じ AI モデルがシリアル化されて、バッチまたはセルフサービスの予測のために外部のアプリケーションとサービスに対して使用可能にされます。 モデルの予測機能を使用するために、最初にモデルのトレーニングに使用されたアルゴリズムを含む同じ機械学習ライブラリを使用して予測機能が逆シリアル化され、読み込まれます。 このライブラリには、モデルと特徴を入力として受け取り、予測を返す予測関数 (多くの場合、スコアまたは予測と呼ばれます) が用意されています。 このロジックは、アプリケーションで直接呼び出すか Web サービスとして公開できる関数にラップされます。 

関連 Azure サービス:

- [Azure Machine Learning](/azure/machine-learning/)
- [HDInsight 上の Microsoft Machine Learning Server (Microsoft R Server)](/azure/hdinsight/r-server/r-server-overview)


## <a name="see-also"></a>関連項目

- [認識サービス技術の選択](../technology-choices/cognitive-services.md)
- [機械学習テクノロジの選択](../technology-choices/data-science-and-machine-learning.md)
